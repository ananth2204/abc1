An introductory look at pacing

Pacing is an SNA mechanism for controlling the flow of data
between components in the network.  Without such a
mechanism it would be possible for the sending Logical Unit
(LU) to inundate the receiving LU with more data than it could
effectively handle in situations when the sender is able to
transmit data faster than the receiver can store or process it.
This can lead to serious buffer shortages and can easily impact
the performance of the entire network.  This article examines
the two major types of pacing available.  It looks at how they
are specified and describes how they are implemented.

The two major types of pacing available are session level
pacing and virtual route pacing.  The underlying technique
used by both is essentially the same.


SESSION LEVEL PACING

Session level pacing is normally based on using a fixed counter
to control the data flow.  This changed to a degree with the
introduction of adaptive pacing in VTAM 3.2 and NCP 4.3.
Adaptive pacing enables the pacing window size to be set
initially to 1 and then adjusted dynamically based on the rate of
traffic and the availability of network resources.  Currently,
adaptive pacing is confined to LU6.2 sessions.

For other than LU6.2 sessions, the pacing window size is
established at session initiation time and is determined,
primarily, by values specified in the LOGMODE table (in the
PSNDPAC, SRCVPAC, SSNDPAC, and PRCVPAC
parameters) or, secondly, in the PACING and VPACING
parameters in the LU, PU, LINE, or GROUP definitions.
Values in the LOGMODE tables override the PACING and
VPACING settings.

There are basically two types of session level pacing: one stage
pacing and two stage pacing.  Quite simply, one stage pacing
takes place directly between two LUs on an end-to end basis,
while in two stage pacing the data flow is regulated, firstly
between one LU and an intermediate boundary node, such as
VTAM or the NCP, and secondly between the boundary node
and the second LU.  VTAM itself uses the network
configuration to determine whether one or two stage pacing
should occur.

Once a pacing value has been agreed upon between the sender
and the receiver, the sender can issue that many requests, but
no more, without receiving a pacing response.  The pacing
response is sent by the receiver when it is in a position to
accept another series of requests.  The pacing response can be
returned to the sender either in a response to a previous request
or as a special response known as an Isolated Pacing Response
(IPR).  This of course would mean that a pacing value of 1
would force a response for every request sent (similar to
operating in definite response mode) and could have very
serious performance implications for devices that do not
normally run in definite response mode.

It is generally recommended that a relatively high pacing value
should be set between the sender and boundary function, with
the value between the boundary function and receiver being
determined by the characteristics of the receiving device type.
Specifying pacing values in the LOGMODE table(s) is
preferable since this method will override any network
definitions and will greatly simplify network maintenance and
performance tuning by restricting the number of places in
which pacing specifications can be defined.


VIRTUAL ROUTE PACING

The values to be used to implement virtual route pacing are
specified as the minimum and maximum window sizes used for
data transmission and are coded in the VRPWSvp parameter of
the PATH macro, where v is the virtual route number and p
denotes the transmission priority (ie 0 for low priority, 1 for
medium, and 2 for high).  The window size is maintained
dynamically between the specified limits.  The default for the
minimum window size is equal to the number of Transmission
Groups (TGs) in the Explicit Route (ER) associated with the
Virtual Route (VR).

The current window size is initially set at the value defined by
the minimum window size and a counter is set equal to the
current window size.  After each message is sent, the counter is
decreased by 1 and transmission continues until this counter
reaches 0 or until a normal VR pacing response is received.  In
the latter case, since no congestion has been detected, the
counter is incremented by the current window size value and a
new series of transmissions begins.

If congestion is detected, the fact will be signalled to the sender
in the VR pacing response and will result in the current
window size being decremented by 1 (providing it is not equal
to the minimum window size).  This process will be repeated
until the congestion is cleared or until the current window size
equals the minimum window size.

Suitable values for VRPWS are dependent on the network
configuration.  An analysis of the data flow across virtual
routes needs to be undertaken so that the existing settings can
be assessed for their suitability.


