SNA-X25 gateway performance


INTRODUCTION

The use of X25 as the standard protocol for backbone carrier
networks is expanding rapidly. X25 is the recommendation for
Open Systems Interconnection (OSI) in the same way that SNA
is the recommendation for Advanced Peer to Peer Networking
(APPN), IBM's answer to OSI. Any IBM site that has
ambitions to become part of the global network community
must encounter X25 networks.

However if there is considerable investment in SNA and
continued commitment to its use then somehow an IBM site
must be able to connect its own internal SNA network to the
external X25 networks. For most IBM sites there is still only
one simple answer, the NCP Packet Switching Interface
(NPSI).

NPSI runs under ACF/NCP on the 37x5 communications
controllers and supports a gateway between SNA and X25. On
the SNA side of the gateway, terminals are supported using
standard PU and LU protocol while on the X25 side of the
gateway, packet switching Virtual Circuits and terminals are
supported. NPSI performs the required protocol conversion
between the two - more or less.

Private Virtual Circuit (PVC) support is reasonably stable but
there are still some problems with Switched Virtual Circuits
(SVCs) relating to difficulties with call set-up and lost calls.
These problems are indicative of the incompatibilities between
SNA and X25 in the areas of session establishment and error
notification.

At the remote cluster on the other side of the X25 network
there are two gateways which are a combination of hardware
and software. A network adapter for the 3174 terminal
controller is available to connect directly to the X25 network.
This requires appropriate configuration support software in the
3174. Alternatively a stand-alone device, the Network Interface
Adapter, can connect between the X25 network port which can
therefore remain unchanged.

NPSI has been established long enough (ten years) as a product
to have had all the bugs removed and the installation process is
now much simplified. However anyone who has had the
misfortune to install NPSI will know that trying to determine
the performance characteristics of the resultant network is like
looking for a needle in a haystack.

One thing is usually certain, the X25-linked terminal response
is much poorer than the SNA equivalent. This article explores
some of the areas to consider and makes some
recommendations which should go some way to addressing this
problem.


BUFFERS

As with most SNA network performance problems,
performance of the SNA-X25 gateway is greatly affected by
the various buffer sizes chosen. In order that sensible decisions
can be made regarding buffer sizes an understanding of the
how the message data is handled is useful.

A message generated on the host and queued to VTAM
undergoes two encapsulation processes.

First the message (termed the Request Unit once in VTAM's
hands) is converted to a Path Information Unit (PIU). An SNA
PIU requires:

o      A 6-byte transmission header

o      A 3-byte request/response header

o      And possibly (optionally) a Function Management Header
      (FMH), which could be between 4 and 20 bytes in length.

The PIU is transmitted across to the NCP running NPSI where
it is then converted to X25 format by a second encapsulation
which adds 3 header bytes (flag, control, and address bytes)
and 3 trailer bytes (2 framecheck sequence bytes and a flag
byte).

Therefore a minimum of 15 bytes is added to the original
message data (RU) by the encapsulation; this figure would
obviously be larger if an FMH is included. An FMH can be
used to set both the response mode in effect and to indicate
whether or not chaining is allowed: use of both of these
protocol characteristics is discussed later.

With normal SNA flow, a PIU is transmitted without change
but, for the X25 flow, if the PIU exceeds the maximum packet
size specified then it must be split or segmented into several
packets before transmission.

This would obviously result in a processing overhead and
therefore introduce a delay. It is therefore important to attempt
to determine an optimum value for the X25 packet size and
match this with the value of NCP MAXDATA so that there
will normally be a fit.


X25 PACKET SIZES

The X25 packet size is not as flexible as SNA and must be one
of four fixed values: 128, 256, 512, or 1024 bytes, which
obviously limits choice.

Typical SNA terminal activity generates data messages or
Request Units of the order of 200 bytes for a screen modify.  A
packet size of 128 would mean that with encapsulation only
about 100 bytes of actual data would be contained in each
packet and that each message will therefore result in more than
one X25 packet.

A packet size of 1024 would mean that PIUs fit comfortably
into each packet. However space will be wasted and, if storage
in the communications controller is constrained, performance
will be degraded.

A simple rule to apply is: the more interactive the traffic, the
smaller the packet size to use. VTAM tracing can be activated
to monitor the actual size of the messages being handled.

A recommendation for a starting point is to chose a packet size
of 256 and set MAXDATA to 250. This should be effective for
interactive traffic where the typical message size is less than
200 bytes. Obviously 'typical message size' will depend on the
applications generating the data.


CHAINING

Remember that the host application will think that it is talking
to an SNA device (even if a somewhat dumb SNA device) and
so may be chaining. Chaining is a method of segmenting a long
message into several small messages. For example, if a real
message is 1000 bytes in length then it may be segmented into
4 actual messages of 256 bytes for transmission.

For applications generating data for transmission across the
SNA-X25 gateway, it is recommended that the use of chaining
is forced. Chaining increases the mainframe and mainframe to
communication controller overhead for message handling but
utilizes the X25 network more efficiently. This is because the
X25 protocol allows several packets to be transmitted before an
acknowledgement is required, therefore an acknowledgement
can be returned to the mainframe immediately. The mainframe
will then continue to process the remainder of the message
straight away.

Chaining can be forced by adjusting application buffer sizes
either in the MODETAB definitions or the application terminal
definitions (as in the case of the CICS and IMS terminal tables
for example). This is done very simply by making sure that the
buffer size is less than the average expected message length.


PACING

Large data movements such as print streams or file transfers
should be isolated and pacing used to control the traffic flow.
Pacing values of 3 or 4 should be tried and the effect observed.

The effect of pacing can be gauged simply by observing the
printer, if it prints continuously then the pacing is correct, if
there are pauses then the pacing value is probably still too low
and should be reviewed.

If possible use SCS for printing since the protocol overheads
are much less than for any other type of print stream. This is
because SCS works using exception response and does not
require a definite response between each message. It is
recommended that, wherever possible, exception response is
used in preference to definite response. It is, after all, the job
of the X25 network to guarantee delivery of the data which
should make the requirement for definite response unnecessary.

If you are having problems with the reliability of the X25
network, don't try to handle it in the SNA-X25 interface,
contact the network supplier! Use of exception response rather
than definite response may require a change to VTAM
applications accessed by terminals using the X25 route but it is
worth the effort of the comparatively simple conversion.


THE NCP

NPSI is a heavy user of the communications controller
processor and storage. If normal SNA traffic must share the
controller with the X25 traffic, it is recommended that use is
made of the ability of the 3745 to run two NCPs
simultaneously to separate the X25 and SNA traffic. Not only
does this make performance monitoring simpler but it enables
different NCP buffer sizes to be selected for optimum X25
traffic.


X25 PARAMETERS

Detailed bit-by-bit recommendations relating to X25
parameters have been avoided so far since manipulating these
is usually time-consuming and quite often unproductive as they
are dependent upon too many unknowns (for example, traffic
levels, message sizes, outboard packet network characteristics,
circuit quality, etc). Indeed parameter manipulation could
actually be counter-productive.

If, however, reviewing and implementing the preceding
recommendations has not yielded any performance benefits
then a more in-depth study will be necessary and for this a
more intimate knowledge of the X25 network may be required.
Having gained this knowledge some guidelines can be applied.

For example, if the network is actually several interconnected
X25 networks or the distances involved are large then the
network propagation delay may be significant and use of
modulo 128 should be considered.

Circuit quality has been a major problem in the past though
much has been and is being done to improve this. If the
network quality is poor and there is frequent error correction
activity in the form of re-transmissions or transmission time-
outs then the retransmission value, N2, should be set to a high
value, the re-transmission time-out value, T1, should be set
high (at least 4-5 seconds) and the window size should be
reduced say to 2 or 3. If the circuit quality is good then
obviously the reverse applies, set N2 and T1 low and increase
the window size.


CONCLUSION

In summary, the SNA-X25 gateway is very slow as it
introduces considerable overheads because of the effects of
buffering and protocol conversion, and the inability of the
software to utilize fully the X25 network capabilities. The
increasing power and capacity of the communications
controller is slowly addressing the performance of the gateway
but in the meantime or pending an unlikely rewrite of the
gateway the effect can be minimized by ensuring that the SNA
applications accessed by X25-linked terminals are correctly
configured and that the X25 network is of good quality.

One last caution: X25 networks consist of a series of store and
forward nodes in which the packets are held before onward
transmission. The capacity of these nodes is obviously limited
and it is possible that heavy use of the network will deplete the
storage capabilities of a node. Such a problem is likely to be
indicated by a sudden, rather than gradual, drop in response
times at high levels of usage. Determining if this is a problem
must be undertaken in partnership with the network supplier
(which could be tricky) and will almost certainly result in
higher network costs for someone.

Brian Alford
Systems Consultant
Aranda (UK)

