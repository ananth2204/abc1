This file illustrates some of the work done at AGCO UK Coventry to use
the Public Domain console automation tool TSSO from file 404 for the CBT
tape (http://cbttape.org/) to control an MVS system running under
Flex-ES.  Our reseller, T3 Technologies UK have been an invaluable
source of help, inspiration and guidance.  We would appreciate any input
from any other source, contact me by e-mail at;

davecartwright@uk.agcocorp.com


The members start with;
TIMER - this is the main clist which drives the other members. This is
invoked by AOF processing by some message which appears at fixed
intervals.  In our case we use an IMS response to another automation
tool, MainView from BMC which causes a specific message (it doesn't
matter which one here) to be issued every 15 minutes. It would be easy
to set up say a JES2 automatic command to generate messages at set
intervals.  I use this clist which is under my control rather than our
scheduling package (CA-7) which is not.
I have two main threads driven by this clist;

PERFORMANCE MEASUREMENT
=======================
When first installed we had some performance problems with our Flex-ES
system.  The configuration had been set up by T3 to our specification
to include a second instance but they left a lot of the details to
default.  This is normally fine for a Development environment, but we
were moving production off an IBM Multiprise 2003 which had an excess of
MIPS and which had a good disk subsystem of an EMC Symmetrix on four
ESCON channels.  Our IMS response times were variable and our overnight
BMP jobs had very elongated run times.  These applications are very
cache unfriendly, but the EMC box had so much cache it didn't matter.
As a first fix T3 helped us set up large cache allocations on selected
disks, this certainly improved things a lot.  We started to monitor
the Flex-ES cachestatistics for our disk controllers. We saw that
sometimes our cache-favoured disks were lightly used while other
normally quiescent volumes had bursts of activity.  We did not want to
tie-up large amounts of memory giving every disk a large cache when most
of the time it would not be used.  Reading the Flex-ES Resource Language
Reference Guide showed that our best bet would be to scrap the
individual track caches and assign cache at the Control Unit level.
This is then shared out by Flex-ES as demand requires. The benefits of
this approach were enormous, IMS response time not only improved, but it
became much more consistent and that was what our Users really wanted.
Overnight BMP jobs benefited as well, but they really got the most boost
from Application Tuning. Jobs came down from hours to minutes when the
Analysts looked at what had grown up over the years and what was really
required.  Some jobs were changed to unload the database, process the
flat file and then reload, which was quicker than random updates on a
huge database.  Some jobs were rewritten completely.
I continue to collect Flex-ES cache statistics, although I now rarely
bother to look at them.   The TSSO members used for this activity are;

CONFIG - Not TSSO, this is our Flex-ES configuration file which can be
tied to the other stuff.  This has grown up from the first install of
our Flex-ES system and needs to be tidied up.  We plan to resurrect the
second instance soon and will rebuild this file at that time.  We
certainly do not hold it up as a model of clarity, but it illustrates
our cache definitions.

CACHE - Every hour this TSSO clist runs commands on the Flex-ES system
to collect Flex-ES cachestatistics for every disk controller defined in
the config file and appends them to a Unixware file.

FLEXJ01 - is a batch job that TIMER submits just before midnight each
day.  It takes a snapshot of Unixware memory usage over the last 24
hours which is appended to the cachestatistics file. This file is then
FTP'd over to a mainframe GDG so I have a history that I can browse from
ISPF.

REPORT - is a sample output from FLEXJ01.

RESET - a clist which is called at the end of FLEJ01 to write an
end-of-file at the start of the cachestastics file ready to collect
another day's worth of data.

STORAGE MANAGEMENT
==================
Another function of TIMER is to automate various HSM housekeeping
commands such as DELVOL. It submits jobs to produce overviews of disk
usage on Fridays so I can decide whether to run defrag jobs before the
weekend. These jobs are not included here, they are simple executions of
MAP3380 and MAP3390 from file 172 of the CBT tape.
The Storage Management members are;

STORAGE - This clist monitors the non-SMS disks and switches them from
STORAGE to PRIVATE if they get too full and vice-versa as they empty.
This function uses SM80, a cut-down version of MAP3380 that I believe is
also in file 172.

SYSDA - Before we installed HSM we ran DMS, which would monitor specific
disks and delete certain files from them daily. The Users insisted that
this function was essential, they could not be asked to delete their own
files created on UNIT=SYSDA. After much grumbling I wrote this REXX to
use the VTOC command off the CBT tape to monitor a few disks that I
called SYSDA.

