Performance and tuning experiences


APPLICATION OVERVIEW

The application under consideration is based on Dun &
Bradstreet's Millennium General Ledger Version 3. This
application runs on a 3090 500E under MVS/XA, and requires
27GB of DASD space of which around 60% is occupied by
VSAM files. At peak times, this application can require up to
17 CPU-hours per day with over 5 million I/Os. Average usage
per day in any month is currently around 7 CPU-hours with 2.5
million I/Os.


PERFORMANCE MANAGEMENT

The principal aim of performance management is to give the
best possible service to the customer. Performance
management establishes a framework within which you can
learn about and tune your application to deliver results as
efficiently as possible.

During an application's development phase, attention is
generally focused on getting that application up and running.
Once it has been delivered into the production environment,
data and usage begin to grow, and the first signs that
expectations are not fully being met begin to appear. The
customer may begin to raise concerns about aspects of the
application such as the service cost, the batch work elapsed
times, the interactive response times, and so on. In order to
minimize such concerns, a performance management strategy
is needed which will enable them to be viewed objectively and
help to identify areas where improvements can be made. This
strategy should also allow for these improvements to be
measured. Having good performance management does not
only mean that the customer gets the best service possible, it
can also mean that the Data Centre machine resource is being
used efficiently. This can avoid, or at least defer, the need to
undertake costly upgrades.

There are four basic elements within performance management:
o      Monitor
o      Analysis
o      Action
o      Review.

Performance monitoring

The first stage in the management of an application's
performance is to measure what is happening. A number of
tools can be used to measure and obtain performance statistics,
and some of these are discussed below. The batch and
interactive measures consider the time and cost aspects of
transaction processing. The file measures consider the efficient
use of storage space, which can have an impact on both batch
and interactive performance.

Although other measures, such as network traffic across each
controller, can also be beneficial, consideration of these
measures is beyond the scope of this article.

Attributes of batch and interactive work are collected by
various system utilities, and their results can be found in a
number of locations.

JCL system messages provide a detailed analysis of each job.
This output can be used to assess the performance
characteristics of each step of a batch job.

Proprietary facilities, such as Dun & Bradstreet's Multiple
Shared Resources management facility (MSR), which allows
improvements to VSAM I/O performance in batch programs
using Millennium I/O service modules, produces reports which
can assist in the performance assessment of a batch job.

Service Level Reporter (SLR) or SAS can be used to report on
pertinent details of interactive and batch work held in SMF,
RMF, or SAS files. These reports should concentrate on CPU
time, I/O, elapsed time, and cost. Omegamon allows
monitoring of individual users in the interactive CICS
environment and can be used to measure in detail the actions of
particularly high-spending users. This data can then be
examined to identify particularly expensive individual
transactions.

LISTCATs or File-AID can be used to determine the condition
of files (number of extents, CI/CA splits etc). The placement of
files on each volume and the spare capacity on each disk can
also be monitored using File-AID.

In order to make performance monitoring an essentially clerical
activity, OPC/A has been used to schedule a number of daily
and monthly reports. These reports are then examined by
clerical staff who look for pre-defined characteristics. The
reports themselves are generated by SAS. The daily reports
provide details of:

o      The previous day's batch work, including, for the General
      Ledger application only, the job name, JES number, CPU
      seconds, I/Os, elapsed minutes, and cost.

o      The previous day's use by each individual user, including,
      for the General Ledger application only, their CPU and I/O
      measures in CICS, TSO, and batch. A summary of each
      cost centre using the application over the 24 hour period is
      also included.

o      The previous day's use by each CICS transaction per hour,
      including, for the General Ledger application only, the
      number of tasks in each hour, the maximum and average
      CPU time, response time, and I/O. A summary of usage by
      CICS transactions over the 24 hour period is also included.

Additionally, Omegamon is used to report daily on CICS tasks
that use more than a specified amount of CPU usage.

The monthly reports provide details of each individual user, for
the General Ledger application only, and their spend in CICS,
TSO, and batch. A summary of each cost centre using the
application over the period is also included.

Measurement analysis

The daily reports described above can be used to identify which
batch jobs are candidates for further examination. Initially, jobs
exhibiting high resource usage or high cost should be targeted
for examination and possible tuning. Later, jobs with a high
elapsed time should be targeted. Consideration should also be
given to the frequency with which each job is run.

The analysis of the batch output JCL system messages can give
guidance about the allocation of buffers for each dataset. This
can vary depending on how the program accesses the data.

Using the daily Omegamon report, 'expensive' CICS tasks can
be identified and reviewed to ensure that they are written in the
most efficient manner possible.

LISTCATs or File-AID can be used periodically to identify file
growth, splits, and other statistics. Measures can then be taken
to reduce splits and keep data within the files' primary extents.
Regular file reorganizations should be performed to assist this.

File-AID can be used to measure the free space on each volume
to ensure that a sufficient allowance is available for anticipated
dataset growth. The placement of datasets across the disk packs
can also be monitored. By monitoring the frequency of access
on each volume and dataset, possible file contention issues can
be detected.

Performance actions

Using the formulae given below, you can develop tabulations
which give guidance on the allocation of buffers to VSAM
files. Consideration must be given to the mode of access
(sequential or random) each program employs to each dataset,
because this can affect the choice of buffers. Allocating too
many buffers can lead to inefficiency caused by unnecessary
buffer management by the operating system, but this
inefficiency is small in relation to that resulting from no
buffering at all.

When using proprietary products such as those mentioned
earlier, consideration must also be given to any guidelines
provided by the product supplier.

In addition to buffers, programs can also be examined for
inefficiencies within their coding. Any found should be
rectified.

Consider what data is needed to meet a particular requirement;
it may be beneficial to develop subsets of that data which will
satisfy the majority of jobs or tasks and occupy a smaller
volume.

Unnecessary data should be archived or deleted. This results in
a smaller file, and can consequently improve performance and
storage problems.

A periodic review of all the files should be undertaken to
ensure that they occupy their primary allocation of space.
Those found not to do so should be redefined with sufficient
primary space.

Regular file reorganizations should be run to reduce splits.
Review file definitions in line with recommendations, and
amend as necessary. Set CI sizes to those recommended by the
package supplier, subject to your Data Centre constraints.

You should conduct periodic reviews of the spread of files
across the disks to ensure that file contention is minimized.

For VSAM datasets, it can be beneficial to use the IMBED
parameter for KSDS files not on cached disks. Also consider
using the REPLICATE parameter on files used in the CICS
system.

For sequential datasets, the use of correct blocking factors will
result in less DASD space being needed to store the same
number of records in a dataset, and reduced batch processing
time because fewer blocks may need to be read or written.

Calculations of VSAM buffer requirements

In order to calculate the VSAM buffer requirements for each
VSAM file, use LISTCAT or another utility to determine the
DATA CISIZE, INDEX CISIZE, DATA CIs per CA, TRKS
per CA, INDEX REC-TOTAL and DATA HI-USED-RBA.

Then, using these values, calculate the number of data and
index buffers required by each file for sequential and random
access using the formulae below.

Establish the datasets accessed and the method (sequential or
random) used by each program in the application.

The buffers required can then be allocated to each dataset
according to the program access method established in the
program/dataset cross reference tables.

The formulae you will need are as follows. For VSAM
sequential access batch processing, the optimal number of
index buffers is 1, and the maximum data buffers is ((2 *
DATA CI per TRK) + 3), where:

o      2 provides for the alternate buffer support.

o      'DATA CI per TRK' determines the number of buffers that
      will provide for full track I/O.

o      3 provides the extra requirement to allow for VSAM
      internal processing and for circumstances where CIs span
      across tracks.

For VSAM random access batch processing, the optimal
number of data buffers is 2, and the maximum index buffers is
(1 + number of index dataset records), where:

o      1 allows for the single sequence set record in storage at any
      one time.

o      Number of index dataset records = (INDEX REC-TOTAL
      - number of sequence set records).

      -      INDEX REC-TOTAL is the total number of index
            records as shown by the TOTAL-RECORDS field in
            the STATISTICS paragraph of the INDEX component
            LISTCAT output.

      -      number of sequence set records = (DATA HI-USED-
            RBA/(DATA CISIZE * DATA CI/CA)).

      -      DATA HI-USED RBA is the high-used RBA as shown
            by the HIGH-USED-RBA field in the ALLOCATION
            paragraph of the DATA component LISTCAT output.

      -      DATA CISIZE is from the CISIZE field and DATA
            CI/CA is from the CI/CA field in the ATTRIBUTES
            paragraph of the DATA component LISTCAT output.

Example tabulations

Some example tabulations for tuning VSAM datasets are
shown in Figures 1, 2, and 3.

The Figures and formulae give a first cut for tuning VSAM
datasets. The buffer allocations can be refined with reference to
the job statistics.

Performance review

It is important, wherever possible, to assess the likely impact
of any change on the application. When applying new or
changed parameters, it may be worthwhile running the job or
task before and after the change and comparing the results.
This enables you to quantify the results of any actions, and use
the knowledge you gain to determine the value of progressing
further with a particular course of action.


INNOVATION ACCESS METHOD

Having tuned our VSAM-based application and obtained some
impressive results, our Technical Support section suggested we
try Innovation Data Processing's Innovation Access Method
(IAM), which had been acquired initially for their internal use.

The IAM product documentation claims that IAM offers an
alternative to using VSAM single index key sequential
datasets, providing advanced file structure, data compression,
and automatic space release, and superiority over VSAM
KSDS or ISAM processing for CICS and batch use; and IAM
requires no change to JCL, application programs or a CICS
system.

If these claims were confirmed, using this product would
reduce our file store requirement and, with less volume of data
to back up, would decrease our back-up and job elapsed times,
thus allowing more jobs to process in each job stream.

A number of proving tests were devised, first to ensure that
IAM would run in a Millennium environment, and second to
measure the potential benefits of using IAM instead of, or
alongside, VSAM.

After examining the statistics collected, the claims made in the
IAM documentation were compared with our findings:

o      IAM claims to cut terminal response and internal CICS
      response times by 30% to 60%. We observed that the
      CICS response times for IAM were 25% to 62% less than
      those for the same CICS task performed on VSAM
      datasets.

o      IAM claims to slash disk I/O by 50% to 90%. We
      observed a decrease of 26% to 70% in file I/O, and a
      decrease of 21% to 70% in job elapsed time when using
      IAM compared with the same batch suite performed on
      VSAM datasets.

o      IAM claims to take 20% to 40% less disk space than
      VSAM. With IAM data compression, a further 20% to
      50% reduction can be achieved. We achieved a reduction
      of 34% to 78% in the space required by the IAM files
      compared to that required by VSAM for the same data.
      The overall saving across the files selected was about 70%.

o      IAM claims to require no changes to JCL, application
      programs, or a CICS system. In practice, we found that we
      had to recompile our 3GL programs without the MSR
      buffer allocation function. We also had to switch off CICS
      Local Shared Resource from those files converted to IAM.
      These were relatively minor modifications, and, in general,
      we found no problems running with IAM files.

Steve Davies
British Nuclear Fuels Ltd (UK)                  c BNFL 1993

