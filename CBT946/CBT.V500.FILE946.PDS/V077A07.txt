VM communications


VM COMMUNICATIONS OVERVIEW

VM/ESA has one of the richest portfolios of communications
products of any operating system platform in the market today.
It should be remembered that when the 9370 was launched, the
two Endicott Labs that were responsible for the design of the
hardware, and of the VM system which ran on it, saw one of
its roles as the replacement of the Series/1 (IBM's all-purpose
communications processor). Although the 9370 has not really
lived up to that role, one of the benefits of the intent has been
the very rich set of communications capabilities which have
been developed for VM to support distributed systems of all
kinds. Also, the Endicott Programming Lab has seen VM as a
host platform for cooperative processing, the interface between
intelligent workstations and mainframe-based applications.


COMMUNICATIONS OF EVERY KIND

It has been said that VM was the first LAN, but implemented
entirely in software. The virtual machine model of computing,
where each user appears to have his own, personal, stand-alone
computer system led very early on to the realization that to
utilize the system effectively a mechanism for communication
between the separate virtual machines was needed.

To provide these facilities in VM, the ability to use the
spooling system to pass files between virtual machines was
developed. It was soon realized that virtual machines on
different VM systems ought to be allowed to communicate in
the same way, and the sequence of products which became
VNET (on IBM's internal systems) and RSCS Networking (to
the outside world) was developed. This also provided a
mechanism whereby RJEs could be hooked into VM.

Soon the ability to exchange files between virtual machines
was extended to message passing via VMCF and then IUCV,
but initially this remained a capability only within one VM
system. What did develop was the idea of allowing users
connected to one system to log-on to another, remote VM
system. This was provided first by PVM (Pass-Through), and
subsequently by allowing VTAM to run in a guest and then
natively on VM. Now a user connected to any VM, MVS, or
VSE system via VTAM can log-on to a VM system remotely
and use its services.

As the total domination of SNA over the networking world has
waned, VM has responded by offering both strong TCP/IP
support, and also (through VTAM) increasing levels of OSI
support. These protocols are now widely supported from the
lowest levels (Ethernet and HDLC) up to the application layer
(SMTP and X.400 mail; FTP, NFS, and FTAM file transfer;
and Telnet terminal emulation). Even network management is
increasingly integrating SNMP (from the TCP/IP world) and
CMIS/CMIP (from OSI) within the SNA NetView umbrella.

The restriction on allowing inter-virtual machine
communications only within one VM system was finally
relaxed by adopting the SNA LU6.2 protocol, APPC, and
implementing it in VM (as APPC/VM). At first this could only
be used within one system or across systems by clustering up to
eight local 9370s on a LAN using TSAF, but subsequently a
gateway was also offered to allow an APPC/VM session to be
established via VTAM with any remote SNA application using
the APPC protocol (not just on VM, but also CICS, AS/400,
OS/2 EE, DOS, AIX, and other vendors products).

The VM Programmable Workstation Communication Services
(VM PWSCS) extends this APPC/VM support to offer a very
high speed (non-VTAM) communications link between a VM
host and LAN-based PCs. This was the first of a series of
products which allow VM to act as a server for a LAN
community of PC workstations (an area pioneered by VM/PC
Bond and its successor the Enhanced Connectivity Facilities,
ECF). This family now includes products like LANRES/VM,
for Novell NetWare connectivity, and WDSF/VM, for host
back-up and archiving of workstation files.

Many of these more advanced products can be used to build
upon VM's role as the original software LAN. In the past,
giving users virtual machines was cheaper than giving them
real ones. This is beginning to change. It is a natural
consequence of the VM architecture, and the extension of inter-
virtual machine communications outside of the host VM system
using industry standard protocols, that a Service Virtual
Machine which provides a service for other virtual machines
can also provide a similar service for other real machines,
namely intelligent workstations distributed locally and around
the world.

It is therefore practical today to consider both distributing the
processing performed in user virtual machines to user real
machines, whilst still offering the same centralized services,
and also to use VM as a platform for delivering services which
existing workstation users need in a controlled, reliable, and
integrated way. What the user should see is a single integrated
service, even though it is actually implemented on an
integrated, heterogeneous network of real and virtual machines.


VM/ESA CONNECTIVITY OPTIONS

Terminal support

Originally, all VM terminals were ASCII asynchronous
terminals (teletypes or TTYs) connected in line mode.
Subsequently the norm became 3270 type devices, locally
attached via a 3274 control unit, or remotely connected using
binary synchronous (bisynchronous) protocols (now obsolete).

Although the line mode TTY support was dropped in VM/XA
SP (except for VTAM devices), that support has been added
back into VM/ESA-ESA (the 370 feature already had the
support). However, line mode use of VM is no longer a widely
used option, and many modern applications have limited
support for line mode users. Most terminals today are either
3270 devices, workstations (eg PCs) emulating 3270 devices,
or ASCII teletypes emulating 3270 devices.

3270 terminals

Today, when a real 3270 terminal is used (or a PC emulator
containing a co-ax card which is pretending to be such a
terminal), the connection is normally to a 3174 or 3274
controller. This controller may be either channel attached to the
host directly or remotely connected via an SNA SDLC
communications line, or over a Token Ring LAN, to a 3745 or
equivalent FEP (which may itself be remotely connected to the
host in the same ways). SNA also now allows these protocols
to be carried to a remote site over X.25.

As an alternative, when an intelligent workstation is used
(usually a PC), it is possible to use a Token Ring connection to
talk to a 3174 connected to the LAN, or to another PC which is
acting as a gateway between the LAN and a 9370 or an FEP.

Two final options available for workstation users are a version
of the TCP/IP Telnet terminal protocol implemented in an
alternative Telnet client application called TN3270 (available
on a wide variety of platforms including PCs and Unix
systems), and an X-Windows based terminal emulator called
x3270 which emulates a 3270 within a window under Unix.

In future it seems likely that IBM will also support 3270
emulators connected to the host over APPC sessions.

ASCII asynchronous communications

When an ASCII asynchronous teletype terminal is used today,
it is likely to be using 3270 emulation so that it looks like a
3270 screen to the VM application. Sometimes the protocol
converter supports a variety of different glass teletypes capable
of performing such emulation (such as the VT100 and IBM's
3101), sometimes it is designed to be used with a specially
written PC application, and sometimes it supports both
mechanisms.

One option is a hardware protocol converter, such as an IBM
3708, the ASCII Emulation Adapter on a 3174, or a third party
emulator such as Hydra or solutions marketed by Adacom,
Rumba, Attachmate, and others. In addition to supporting
dumb teletypes, the two IBM solutions support a specially
written PC application called FTTERM (although they cannot
be used with IBM's Personal Communications/3270 package).
The Rumba solution is designed for use with Rumba's
Windows 3.x based terminal emulator and application front end
tool, while Attachmate's works with their Extra! 3270 terminal
emulator.

An alternative is to provide 3270 emulation via a protocol
converter package running on VM, such as SIM3278 (from
Simware), Relay, or Packet/3270. This sort of product may run
either in VM or as a VTAM application. In addition to
supporting dumb teletypes, these packages normally include
intelligent PC front ends, and perhaps a Macintosh front end as
well. A variety of transports such as TCP/IP may be supported
as well as asynchronous dial-up. They often also offer
sophisticated techniques for improving performance, such as
datastream optimization or Simware's ability to maintain a local
cache of screen images on the workstation.

In addition to using these packages on a directly dialled
telephone line, they may be used over the public X.25 packet
switched networks to provide lower cost access from remote
locations or a travelling laptop computer. Indeed, Packet/3270
was specifically written for this environment, although some of
the other packages now work equally well in this environment.

An alternative approach for remote access is to provide a
VTAM link from the target VM system to IBM's Information
Network (IIN), which then provides access points around the
world which the remote or laptop user can dial using FTTERM
or a dumb teletype emulation package. In some countries, IBM
offers special ASCII asynchronous dial-in ports to IIN which
support the ASCII asynchronous capabilities of its top of the
range Personal Communications/3270 terminal emulator.

In addition to terminal emulation, these PC packages usually
offer a file transfer capability to upload/download files, and the
HLLAPI which allows applications to control the host session
to automate routine tasks or implement application front ends.
They may even offer an APPC option.

File Transfer

The most common networking mechanism used with VM is
RSCS, which allows file transfer to other VM systems, to
MVS and VSE systems, and to AS/400s (using NJE protocols),
as well as to any other system supporting the de facto RJE
protocols 2780 and its SNA successor 3780. Links may be
SNA based, may use a CTCA for direct connections between
CPUs, or may use the old bisynchronous protocol.
Additionally, RSCS drives 3270 printers and suitably
connected ASCII printers and plotters.

For MVS systems, RSCS communicates with NJE to allow
files to be exchanged with the JES spool. Files from an MVS
application may be routed to printers on VM, or the virtual
card readers of specific virtual machines (via the ROUTE JCL
card). TSO also now supports the NETDATA file format used
by VM's SENDFILE and NOTE commands. In addition to file
transfer, messages are supported (which on VM are delivered
as CP messages).

On VSE systems, RSCS communicates with POWER.
Although traditionally VSE systems running under VM have
passed files to VM and its devices via the virtual punch of the
VSE system, the use of a POWER to RSCS link provides more
flexibility and better routing capabilities.

RSCS runs under the control of the GCS component of
VM/ESA. When used in conjunction with an SNA link, RSCS
runs in the same group as VTAM and uses its services. When
used only with non-SNA links, RSCS still runs under GCS but
does not require VTAM to be installed.

When RSCS is used on a VM system it provides a logical
extension of the VM spool to allow files placed in the spool to
be moved to either the spool area of a remote (VM or non-VM)
system, or to be transmitted to a device not directly connected
to the VM system.

An alternative, increasingly important networking product for
VM is TCP/IP. The File Transfer Protocol (FTP) of TCP/IP
allows files to be exchanged between systems supporting the
protocol. Unlike the RSCS approach, FTP uses explicit GET
and PUT commands to allow a user to move a file from one
location on one system to another location on another. TCP/IP
is widely used in the Unix world, and is becoming a popular
way to link workstations to servers in client-server systems.

The third inter-system file transfer mechanism supported by
VM is the OSI FTAM standard, as implemented in IBM's
OSI/File Services (OSI/FS) product. However, this protocol is
not widely deployed.

Remote file access

Another mechanism which can be used for distributing files,
closely related to file transfer, is remote file access. VM
supports two protocols of this type. SFS will communicate with
remote VM systems also running SFS to allow users on one
system to remotely access files in the shared file system on the
remote system. This support uses APPC/VM to communicate
between the two systems, and therefore a remote APPC
communications path is needed between the VM systems (ie
either via VTAM and an SNA network, or locally in a TSAF
cluster).

The second remote file access mechanism supported is Sun's
Networked File System (NFS), the de facto standard for remote
file access over TCP/IP. TCP/IP for VM offers NFS server
support, allowing remote workstations to access files on the
VM system and create files on VM. Note that client support is
not currently offered, so CMS users cannot access files stored
on remote systems.

As yet, VM/ESA does not support the SAA remote file access
protocol, Distributed Data Access (DDA).

3270 file transfer

One other file transfer mechanism to/from VM is the
IND$FILE command. This is used to allow workstations to
transfer files to and from VM over a 3270 terminal session, and
is used by many workstation terminal emulators from IBM and
third parties on DOS, OS/2 EE, and AIX (or indeed other Unix
systems).

Note that the '$' in IND$FILE is, in fact, the currency symbol,
and hence varies according to code page. In the USA, this is
the dollar sign. In the UK, it is the pound sign, although the
utility is still often referred to as "Ind-dollar-File". In other
countries, a variety of other graphics are associated with this
character.

Care must therefore be taken when using a terminal emulator
supporting IND$FILE to configure the file transfer command to
be used according to the code page in use on both the
workstation and the host (or rather the 3174 control unit, or the
hardware/software providing the equivalent function).
Although this is comparatively straightforward when the
workstation and controller are in the same country and
configured in the same way, when connecting remotely to
systems in another country (eg via ASCII asynchronous
terminal emulation) experimentation is usually required to
make this function work. If you are having this problem, a
frequent solution is to create an INDFILE EXEC which calls
the IND$FILE command, and configure your terminal emulator
to use that command for file transfer instead.

The user interface to IND$FILE usually takes the form of
SEND and RECEIVE commands on the workstation which
allow a file to be stored on VM, or downloaded from VM to
the workstation.

The Enhanced Connectivity Facilities also provide a
mechanism to transfer files between a workstation and VM by
allowing the host file system to appear as an additional drive on
the PC.

Electronic mail protocols

In addition to these file transfer mechanisms, a number of
special purpose electronic mail protocols are supported by VM.

SNA Distribution Services (SNADS) is a mail file transfer
protocol widely used in MVS (by DISOSS) and other systems
(eg the AS/400). This protocol is not directly supported by VM
or OfficeVision/VM, but instead the OfficeVision/VM DISOSS
bridge will send mail via RSCS to an MVS application which
will give the mail to DISOSS (which can turn it into SNADS
traffic for, say, an AS/400). Similar ad hoc solutions are
available for direct links to the AS/400 (again using an RSCS
link) and OfficeVision/2 (using RSCS and an SVM which
communicates with the OfficeVision/2 server over a 3270
session). Alternatively, IBM offers Soft.Switch Central if
native SNADS support is required on VM.

Simple Mail Transfer Protocol (SMTP) is the TCP/IP electronic
mail protocol, and is supported by TCP/IP for VM, which also
offers a replacement for the CMS Note command which can
format mail for delivery to SMTP destinations.

X.400 is the OSI standard for electronic mail interconnection,
and is supported both by a set of products running with IBM's
OSI product, OSI/CS, and also by Soft.Switch Central.

APPLICATION PROGRAM SUPPORT

The primary mechanism for inter-application communications
on distributed VM systems is APPC/VM. This implements the
APPC verb set to allow a CMS application to communicate
with:

o      Another CMS application on the same system

o      A CMS application on a different VM system

o      An APPC application connected anywhere in the SNA
      network running on any platform.

Indeed, a virtual machine can even have an APPC/VM
conversation with itself, but this is not likely to be useful
unless it is running a multitasking supervisor (eg CMS
Pipelines or the Server Tasking Environment/VM).

CMS offers an Assembler level interface to APPC/VM. This is
implemented via a small number of new APPC/VM specific
macros, plus some extensions to the existing IUCV interface.
Note that APPC does not define a platform independent API,
rather it defines the functions which must be implemented.

The Common Programming Interface Communications (CPI-C,
now called CPI-CI in SAA) is the SAA-defined API to APPC.
This is implemented via CMS Callable Services Library (CSL)
calls to provide an interface to APPC/VM from REXX or other
high level languages.

APPC provides a mechanism for establishing sessions between
applications, passing data, and terminating the session. Each
session is half duplex (ie transmission is permitted in only one
direction at a time), but applications normally establish two
sessions to allow full duplex, bidirectional conversations. An
application may normally define any number of parallel
sessions, up to a defined limit. APPC also defines security
mechanisms to allow the authorization of conversations. In
SNA terms, each APPC/VM application is an LU of type 6.2.

One of the additional (optional) facilities of LU6.2 which is
offered by VM/ESA is the sync point architecture, which
provides application coordination, resynchronization and
logging to assist in implementing 'two phase commit' protocols.
It is implemented in CMS as Coordinated Resource Recovery
(CRR). This allows multiple applications to perform updates to
external objects in a coordinated fashion, with all updates being
either 'committed' or 'rolled back', and is implemented over
APPC/VM in a similar way to CPI-C.

The ability to establish APPC/VM conversations within one
VM system may be convenient, but the mechanism really
comes into its own by allowing communication between
applications on different VM systems or between a CMS
application and an application running on a different host
system.

The TSAF SVM provides a mechanism for linking up to eight
VM systems into a TSAF Collection, which allows applications
running on any of the systems to communicate with each other
via APPC/VM.

In a TSAF Collection, the different TSAF SVMs can be linked
via:

o      a CTCA (or a 3088 link)

o      a bisynchronous communications line

o      an Ethernet or Token Ring connection using the
      appropriate adapter on a 9370 or rack mounted ES/9000.

Within a TSAF Collection the protocols used are designed to
be highly reliable, supporting multiple routes between nodes
and full, automatic recovery on link failure (providing an
alternative path exists), without the application being involved.
Collections may also be dynamically partitioned and then
reunited when links fail and are reconnected.

The TSAF Collection is designed to work as a local cluster of
machines, and one or more of the TSAF machines in these
collections may be linked over an SNA WAN via APPC/VM
VTAM Support (AVS) to another TSAF system in a different
collection. AVS is a VTAM application which runs under GCS
in the same group as VTAM on the VM system, and
implements a gateway to the whole TSAF Collection for the
rest of the SNA network. This allows multiple collections, each
of between one and eight systems, to be inter-linked over a
wide area via the SNA backbone network. Note that every VM
system in the TSAF Collection does not need to be running
AVS (or indeed VTAM) - only one gateway somewhere in the
collection is needed.

The APPC/VM documentation (and implementation) assume
that there are fundamentally two types of APPC application,
Resource Managers (servers in normal terminology) and User
Programs (or clients). In practice, of course, APPC provides a
general mechanism which can be used just as easily to provide
communications between two servers, or even two users, as it
can to provide what has recently become the accepted client-
server model. Given the single-tasking nature of CMS, it is
unlikely that APPC-style communications will occur between
users (as both users would need to run their respective
application for communication to occur). This is why the SVM
model was created in VM, and this is why the APPC/VM
client-server model works well in that environment. Similarly,
many server-to-server applications use a master and slave
protocol, and hence the client-server model can still be applied.

APPC/VM in fact defines three types of resource. A local
resource is unique to the local VM system, but not to other
systems in the TSAF Collection or through the AVS gateway.
A global resource is known throughout the TSAF Collection
and may be accessed via the AVS gateway. A private resource
is described later.

There is one significant distinction between access to global
resources within the collection and access to the same resources
via the AVS gateway. When an application identifies itself as a
local or global resource, CP records its name dynamically so
that access can then be granted to any requesting APPC/VM
application on the same system. In addition, for global
resources TSAF is informed when the resource identifies itself,
and so makes that resource name available throughout the
TSAF Collection. However, this sort of automatic registration
does not occur for the AVS gateway. If a global resource is to
be accessed by remote applications via AVS, it must be
statically defined in the appropriate AVS configuration table.
Indeed, AVS will map global resource names to an external
LU6.2 name (an LU name plus a transaction program name),
thus removing the need to make the resource name unique
throughout the SNA network.

On the other hand, the third type of resource, a private
resource, does not identify itself dynamically in this way.
Rather it is defined in the local system directory as a virtual
machine, with the user-id being the same as the target LU
name for the resource. When a user connects to this APPC/VM
resource, from inside or outside of the TSAF Collection, the
virtual machine will be logged on via AUTOLOG ready to
process the request. When the virtual machine becomes idle (ie
has no IUCV or APPC connections and has not been active for
30 minutes), it will be forced off. A single virtual machine may
be defined to provide multiple private resources, but the
requests will be handled sequentially not in parallel.

Configuration and use of APPC/VM, TSAF, and AVS are
described in detail in the Connectivity Planning,
Administration and Operation manual for VM/ESA. The
Assembler level interface to APPC/VM, and the CPI-C and
CRR interfaces, are described in the VM/ESA CMS
Application Development Guide for Assembler and CMS
Application Development Guide, respectively.


OTHER APPLICATION INTERFACES

In addition to SNA oriented APPC support, VM is able,
through its TCP/IP product, to offer support for the Sockets
interface (on top of which many TCP/IP applications are built).

Alternatively, in the OSI world OSI/Communication Services
(OSI/CS) offers an OSI protocol stack on VM/ESA allowing
applications to communicate over X.25 and LAN networks
with other applications supporting the OSI protocols. The
VTAM OSI RPI feature allows applications using the same
API to be run on a system not connected to the OSI world and
to communicate across an APPC session to an OSI/CS system
which provides a gateway to an OSI network, thus allowing
such applications to be distributed in an SNA network without
requiring wholesale deployment of OSI protocols in parallel to
SNA protocols.


VTAM PRODUCT FAMILY

When ACF/VTAM Version 3.3 is used with the VM/ESA-ESA
feature, it is able to exploit the 31-bit addressing capabilities of
GCS, thus providing storage constraint relief for large VM
systems. In addition to core VTAM services being 31-bit
exploitative, VM SNA Console Services (VSCS), the VTAM
component which interfaces to VM/ESA CCS to allow remote
terminals to log-on to VM or dial to VM applications, can also
utilize memory above the 16MB line.

This release of ACF/VTAM also supports ESCON channels on
VM/ESA, and the VTAM First Failure Data Capture (FFDC)
capabilities for non-disruptive generation of dumps for certain
error conditions. VTAM Version 3.4 for VM/ESA provides
many additional VTAM capabilities including Token Ring,
IEEE 802.3 (Ethernet), and FDDI connections via the 3172
Interconnect controller, and the OSI RPI.

The NetView family of products, which provide network
management for host-based SNA networks, are also supported
on VM. Broadly their function is the same on VM as on MVS.
There is little VM-specific functionality.

One specific example is NetView Distribution Manager
(NetView DM) which uses SNA/File Services (SNAFS), a
derivative of SNADS, to distribute service to remote systems,
and microcode to 3174 controllers (SNAFS, together with
SNA/Management Services and SNADS, provides the
architectural basis for the NetView products). This is provided
to allow centralized system management of distributed systems,
and can be used (on VM or MVS) together with the
VM/DSNX running on VM at the remote site to distribute new
versions of VM components, applications, data, or other
objects, and then invoke procedures to update the remote
systems to use these new objects - DSNX effectively acts as a
'catcher' for service distributed by NetView DM.

Another NetView product, the NetView File Transfer Program,
offers high volume, store and forward data transfer via APPC
between VM, MVS, VSE, and AS/400 systems over APPC
links in an SNA network (with optional file compression). This
includes transmission of VSAM files.

NetView Access Services is a VTAM-based multi-session
terminal monitor. It also offers security features (allowing
RACF, or an equivalent, to define which user can access which
VTAM applications) and a shadow capability (to allow a Help
Desk operative, for example, to look at a user's session).
Similar multi-session products have been available on VM for
some time (for example TUBES) and the latest version of Pass-
Through (PVM) has similar capabilities.


REMOTE SPOOLING COMMUNICATION SUBSYSTEM

RSCS is the prime file transfer and printer spooling mechanism
for VM. Originally included as part of VM/370, when VM/SP
was announced RSCS was split out as a separate program
product, RSCS Networking. Version 2 of that product offered
SNA support for the first time by running under GCS,
alongside VTAM, and allowing the use of SNA transports to
communicate with remote systems.

RSCS Version 3 represents a major enhancement to the
product, not so much because of any major new features but
because it provides a whole set of incremental improvements to
help implement robust, powerful, and easy to administer
networks. Key new features in Version 3 are:

o      Significant performance improvements over Version 2.

o      A Generalized Programming Interface to allow customers
      and vendors to write new line drivers.

o      Enhanced command responses, and a new Command
      Response Interface to deliver the results of a command in a
      parsable form to a user application.

o      Return of a spool file to a user informing them of
      undeliverable files.

o      An Event Scheduling Manager to perform certain functions
      automatically at specific times.

o      Inclusion of a line driver for the AS/400 (previously
      requiring a PRPQ).

o      The inclusion of sample security exits (eg to intercept files
      with specific names).

o      An EXEC to automatically exploit RSCS List Services
      which will allow files sent to remote location to be sent
      once and 'fanned out' only when necessary.


VM PASS-THROUGH

VM Pass-Through (PVM) allows multiple VM systems to be
connected together, and then allows a user on a terminal
connected to any one of them to log on to any of them. It
utilizes the Logical Device Support (LDEV support) in CP to
create a logical 3270 session. CP then gives PVM the 3270
datastream which it would normally send to the terminal, and
PVM transmits it to the remote user's terminal instead.

When a user connects to the Pass-Through virtual machine, he
is presented with a menu of remote systems to which he may
connect. The user can connect to PVM via CP DIAL from a
3270 terminal, or alternatively via a command from CMS. In
the latter case, the ability to disconnect temporarily from the
remote session and return to the local CMS session is provided,
as well as a screen capture capability which will write the
remote screen image to a CMS file.

PVM acquired bisynchronous (3270) terminal and printer
support when VM/XA SP was announced without this
function. (PVM also provides this support for VM/ESA-ESA.)

PVM must be implemented on each system to which the user is
to be provided access. The links between these systems may be
via a CTCA (including a 3088 and ESCON with Version 2),
via a bisynchronous telecommunications line, or over an
APPC/VM session (which may be implemented via VTAM
over an SNA network, or locally within a TSAF cluster).

Version 2 of PVM adds multiple session support and the ability
to program in REXX macros to automate session establishment
and other activities on the remote session. It also provides a
VTAM gateway to allow 3270 sessions with VTAM to be
established without the need to create a local CP 3270 session
and then dial that to VTAM.


TCP/IP FOR VM

TCP/IP Version 2 for VM (often called FAL from its product
number, 5735-FAL) is the implementation of the TCP/IP suite
on VM.

IBM has a TCP/IP product for DOS, together with one for
OS/2, native support in AIX for the RS/6000, and host
products for MVS and the AS/400.

TCP/IP for VM supports the major applications in the
protocol suite

Telnet

Remote terminal log-on is supported, both inbound to VM and
outbound from VM terminals. Both line mode support and
3270 datastreams are supported. The 3270 support both allows
a convenient method for a user on one VM system using
TCP/IP to log-on to a remote VM system in fullscreen mode
(in much the same way as using PVM from a CMS session),
and also allows a suitable workstation implementation (such as
TN3270 provided with the PC feature of TCP/IP, or the x3270
application for X-Windows on Unix systems) to access the VM
system in fullscreen mode.

FTP

The file transfer protocol is supported, as either a client
(originator) or server (target) of a transfer request. Specific
support is provided to preserve fixed record format file
structure in transfer between VM systems, as well as
supporting traditional, stream-oriented file transfer. RACF
support allows CMS file access to occur without logging on to
the target system.

SMTP

The Simple Mail Transfer Protocol allows the exchange of
electronic mail with other TCP/IP systems (or non-TCP/IP
systems via appropriate gateways). Alternative versions of the
CMS Note and SENDFILE command are provided to allow
notes and files to be sent via SMTP mail. Received notes are
sent to the user's reader. Access to the SMTP gateway may
optionally be restricted to a list of registered users, with mail
to/from other users being rejected.

REXEC

The Remote Execution protocol client allows a CMS user to
execute a command on a remote system providing a REXEC
server, and receive back the results.

LPR/LPD

Support for TCP/IP 'line printing' applications allow remote
applications to print files on local VM printers and RSCS
printers, and allows VM users to print on remote systems
supporting LPR/LPD.

X-Windows

Support for X-Windows clients allows applications running on
VM to drive an X-server (ie terminal) on a remote system. This
allows a user on an X-Terminal, a PC with X-Windows
support, an RS/6000, or any other workstation running Unix to
access VM-based Unix applications. A VM terminal cannot
access remote Unix applications, however.

Motif

Provision of the OSF's Motif toolkit allows applications written
to this interface to be implemented on VM and be used by
remote Unix users, giving them the typical Motif look-and-
feel.

GDDM

Graphics support allows users on remote X-Windows terminals
to access GDDM applications on VM within an X-Window.
This allows all of the GDDM applications to be used (such as
ICU for charting) as well as supporting user-written
applications which use the GDDM libraries to drive the screen.

SNMP

Support for both the SNMP agent and monitor protocols is
offered. SNMP monitor support allows TCP/IP for VM to act
as a NetView focal point to allow TCP/IP-based networks
utilizing SNMP to be managed from NetView. For example,
asynchronous events (SNMP TRAPS) can be forwarded to
NetView, and sample NetView CLISTs, written in REXX, are
provided to demonstrate the use of NetView to manage an
SNMP system. The agent support allows TCP/IP for VM to be
managed by other SNMP management products.

Sockets

The Berkeley Socket library is the de facto standard API to
TCP/IP, and may be used by user applications. IUCV is used
to communicate between the socket library running under CMS
and the TCP/IP service virtual machines.

RPC

Sun's Remote Procedure Call library is provided for application
use, using the External Data Representation (XDR) protocol to
allow the exchange of data between applications with different
hardware architectures.

NCS

Apollo's Network Computing System libraries are provided as
an alternative remote procedure call protocol (using the OSI
ASN.1 data encoding standard for transmission).

Domain Name Server

Domain Name Server will allow VM to hold domain data for
name resolution. SQL/DS is a prerequisite for full use of the
Domain Name Server. An SMSG interface is offered for
management of the server.

Kerberos

Support for the Kerberos authentication service is provided to
perform validation of communication requests for access
control to servers. Specifically the Kerberos server is provided,
together with administration and database management
applications. In addition the Kerberos library is provided for
applications wishing to authenticate conversations. Kerberos is
actually provided as two non-chargeable features, one for use
in the USA (with DES encryption) and one for use outside
(without DES).

Additional features offered with TCP/IP for VM

NFS

This chargeable feature offers server support for Sun's Network
File System, the de facto standard for remote file access over
TCP/IP. This allow NFS clients to access the CMS file system
from remote workstations (although client support, which
would provide access to files stored remotely from CMS, is not
offered). A RACF interface and user exits are also offered for
access control.

Soft Copy Documentation

A free feature offers on-line publications in BookManager
READ format. The various APIs described are provided for C.
In addition both C and Pascal interfaces to the TCP and UDP
protocol boundaries are offered. Authorized CMS user-ids may
also access the IP layer directly.

TCP/IP for VM supports a rich set of connectivity options.

3172

The 3172 Interconnect Controller (Model 1) channel attaches to
the VM host and may be configured for Ethernet or Token
Ring attachment. The 3172 is a MicroChannel-based control
unit for high performance connectivity to LANs.

8232

The predecessor to the 3172, the 8232 LAN Channel Station,
installed in an industrial PC gives Token Ring, Ethernet, or PC
Network support.

9370

The following integrated controllers are supported on 9370 and
rack mounted ES/9000 (9221) systems:

o      Ethernet adapter (not supported for NFS)
o      Token Ring adapter (4 or 16Mbs)
o      X.25 Communications Subsystem

37xx

A 3745 or 3720 front end processor (or equivalent), together
with VTAM, NCP and NPSI, are needed for X.25 support.

HYPERchannel

The NSC HYPERchannel with an IBM channel adapter is
available.

TCP/IP general

One particularly interesting application of TCP/IP for VM is to
allow access to an SNA backbone network to carry TCP/IP
traffic between locations. The SNALINK component
communicates over the backbone via an LU6.2 session
(although it does not use APPC/VM, instead implementing its
own APPC support to VTAM).

As an alternative to SNALINK, multiple TCP/IP for VM
systems can be linked via PVM sessions between hosts. This
allows connection across any PVM to PVM link, including a
CTCA or TSAF cluster without VTAM, as well as over an
APPC/VM link via VTAM.

Editor's note: this article will be continued next month.

Stuart McRae
Soft.Switch (UK)                                    c Stuart McRae 1993

