VM/HPO to VM/XA conversion experience

Recently we have been through a conversion from VM/HPO 4.2
to VM/XA SP 1 and I would like to share our experiences with
other users.

The conversion to VM/XA was necessary because we are doing a
conversion from VM/VSE to MVS/XA on one machine.

Before the conversion we were running VM/HPO with five VSE
machines and about 40 CMS machines on a 4381 model 14 dual
processor with 24 MB of storage (see Figure 1).

Since the conversion we have been running VM/XA with five
VSE machines, one MVS/XA machine and one VM/SP second-
level machine containing the above-mentioned 40 CMS users.  At
the same time we upgraded our CPU to a 4381 model 24 with 48
MB of storage.

Compared with the VM/HPO library the VM/XA library has been
completely reorganised and has a set of binders and binder-sleeve
inserts.

In addition to the VM/XA library we received a manual, VM/XA
System Product Release 1 Installation Experiences (GG24-3226),
which must be ordered separately.  I would strongly recommend
ordering this manual as it explains how to install VM/XA on a
running VM/HPO or VM/SP system, thus saving yourself many
hours of work during nights and weekends.  Actually you are able
to load all mini-disks and generate a complete VM/XA system on
a running VM/SP or VM/HPO system.  The only thing you can't
do is IPL VM/XA as a guest.

One of the first manuals to look at (apart from the above
mentioned) is the VM/XA Conversion Notebook, which is part of
the VM/XA library.  This manual explains the differences
between VM/HPO and VM/XA.

Below are listed some of the differences, to give you an idea of
what this conversion means:

%	VM/XA runs in XA mode (as the name implies), which,
amongst other things, means a different channel architecture
and a slightly changed instruction set compared with 370-
mode, which VM/SP and VM/HPO are running in.

%	Even though VM/XA runs in XA mode it supports guests
running either XA mode or 370 mode, whereas VM/HPO
supports only 370 mode guests.

%	Needless to say, your processor must support XA mode.  The
change from 370 mode to XA mode is, however, simply done
through an IML on a 4381.

%	On the 4300 series you will now have to make an IOCP
(Input/Output Configuration Program), which is an
Assembler-like program that describes your I/O configuration
to the hardware (or microcode, to be specific).

An IOCP is generated stand-alone in 370 mode, meaning that you
have to shut down your VM/XA system, re-IML to 370 mode, run
your IOCP gen, save your new IOCP, re-IML to XA mode and
IPL your VM/XA system again.  This is probably to encourage
you not to change your I/O configuration too often.

As far as I know an IOCP has always been required on a 3090.

%	The CP part of VM/XA has changed considerably.  One of
the first things that you spot is that the good old well-known
DMK prefix of all modules has changed to HCP.

%	The DMKRIO has been replaced by a HCPRIO but no longer
contains information about control units or channels; only the
I/O devices are left.

%	The DMKSYS has changed slightly into a HCPSYS, where
the concept of swapping and preferred paging has
disappeared, being replaced by block paging, which is
something between paging and swapping.

%	In order to get ATTACHed to the system at IPL all your disk
volumes, not only your CP volumes, now have to be specified
in HCPSYS.  An alternative solution is to let AUTOLOG1
attach the disks to the system at IPL: this is certainly more
flexible than doing a sysgen every time you add or change a
disk volume label.

%	The DMKSNT has been completely removed.  Named Saved
Systems (Saved Systems in VM/SP terminology, eg CMS)
and DisContiguous Saved Segments are now defined and
generated on-line without having to do a sysgen.  They are
kept in the spool area and may be manipulated using ordinary
spool commands, for example QUERY, PURGE, SPTAPE.
They are, of course, not erased during a cold start.

%	Like the DMKSNT, the DMKFCB, -UCB, -UCC, and -USS
are replaced in a similar fashion.  This again relieves you of
the burden of doing a sysgen just to add an FCB.  You may
now also stop worrying about these modules exceeding 4K in
size as they are no longer part of the CP nucleus.

%	The tools for making a sysgen have also changed; the
GENERATE EXEC is replaced by ITASK EXEC, which at
present can only be used for making a nucleus.  From SUP
8805 it cannot be used to assemble the RIO or SYS.

%	The CMS part of VM/XA hasn't changed much.  All modules
do still have the old DMS prefix.  The CMS supplied is a
Release 5 CMS based on the CMS of VM/SP Release 5.

	By default you no longer have a CMS and a CMSL, although
nothing will prevent you from having it.  Instead you will
have one CMS running in 370 mode and one CMSXA
running in XA mode

%	In XA mode a virtual machine may be defined up to 999 MB;
in 370 mode the limit is still 16 MB.

%	In VM/XA you now have the possibility of using several
directories: a primary that you normally use, and one or more
alternatives which may be used for test or emergency use.
The search for a directory starts at the residence volume and
continues through the list of volumes defined as CP-owned
until a valid directory is found and brought on-line.  If no
valid directory is found an OPERATOR user-id is created
which may be used to bring a directory on-line.

When planning the conversion be careful to check whether your
software, particularly that in the CMS environment, supports
VM/XA.  Remember to check both with IBM and other suppliers.
In our case we had to establish a second-level VM/SP system for
development because our old source-management system
(PANVALET/VM) didn't work in VM/XA.

The conversion to MVS/XA was scheduled to last 10 months and
we wouldn't introduce a new source-management system for such
a short period of time.

One good piece of advice is to avoid having a second-level VM
system whenever possible.  It usually means that your system will
become much more complex and vulnerable.

Figure 2 shows our current software set-up: VM/XA on the top, a
second-level VM/SP system, five VSE machines and one
MVS/XA machine.

Jobs are transmitted between a user at the second-level VM
system and a VSE machine via two RSCS-machines connected
through virtual CTCAs.

Output is returned from a VSE-machine via a POWER PNET to
RSCS connection using the BSC protocol and two lines in our
3720.

Unfortunately we didn't have the time to upgrade our VSE system
to VSE/SP 3, which includes POWER CTCA support.

Furthermore, we are using a multi-session product (TUBES) that
allows a user at the second-level VM system to dial into a VSE
machine.  This is done by having two TUBES machines (TUBES
runs in a disconnected machine), one at each VM level, and
connecting them via virtual CTCAs, like RSCS.

Although VM/XA SP is a fairly new product, it seems to be
stable.  We have been running VM/XA since November '88
without one single CP abend.  However, I must admit that we are
not using CMS very much.

Current VM/XA is now Release 2 and it differs slightly from
Release 1, which is described in this article.  The main area of
change is the directory: amongst other things the concept of
profiles in the directory is now supported in VM/XA.

During test we discovered strange performance problems.
VSE/CICS response times began to fluctuate from 0.25 to more
than 30 seconds in a lightly-loaded system with virtually no users.
With assistance from IBM we found out that the problem was due
to the VSE machines being put on the eligible list for long periods
of time.

The solution was to change the STOREBUF default values in
order to tell VM/XA to overcommit storage.  In our case 'CP SET
SRM STORBUF 250% 220% 200%' has proved satisfactory.

Compared with VM/HPO, VM/XA is a storage gobbler.  The
nucleus takes about 2 MB, which is really unavoidable, but there
are areas in which you can save a lot of real storage.  With 48 MB
of real storage the trace area defaults to 1 MB, which can be
reduced considerably.

If you have defined a V=R area, CP by default puts aside an extra
area of 1 MB for control information; this area is also a good
candidate for reduction.  The VM/XA SP Planning Guide contains
an EXEC that helps you to determine the size of this area.  The
size of both areas is controlled from HCPSYS.

The performance options known from VM/SP and VM/HPO -
SET FAVOR, SET QDROP, SET PRIORITY - have been
replaced by SET SHARE and SET QUICKDSP.

SET SHARE allows you to guarantee that a given virtual machine
is to receive at least a certain amount of resources.  In contrast to
the old SET FAVOR, which only applies to CPU, SET SHARE
applies to CPU, storage and paging.

SET SHARE may be specified in two ways: as an absolute
percentage of all available resources, or as a percentage relative to
other virtual machines.

Steen Spuur Hansen
Systems Programmer (Denmark)	) Xephon 1989

