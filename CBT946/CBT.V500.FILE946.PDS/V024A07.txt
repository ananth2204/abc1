 SQL/DS basic performance and tuning
The information provided in this article is based upon results gathered from a
production environment using SQL/DS Version 1.3.5, under VM/SP on IBM's 4381
Model 11 CPU with 8 Mbytes of real memory, and with two 3380s on the same
channel.  The tables involved consist of a Donor Profile table with 1 million
rows, an Account file with 1.2 million rows, and a transaction table with
10 000 rows.  The update cycle runs in two hours; down from an original run-time
of 15 hours.
The first objective for the DBA is to get SQL/DS to buffer as much information
as possible.  The overall performance of SQL/DS is highly dependent on the
amount of real storage allocated to the SQL/DS virtual machine.
In general, SQL/DS system performance is dictated by the setting of the SQL/DS
start-up parameters.
LOCKING
The first issue that most shops encounter is locking or concurrent access to the
tables that are stored in the database.  Usually, lock escalation prevents other
users from using a particular table.  Lock escalation occurs when SQL/DS
increases the size of the data being locked.  SQL/DS will always escalate a lock
to the DBSPACE level.
An example of this is when a USER A issues a SELECT on a table that results in
more than 500 rows being returned, and USER B issues an UPDATE on the same
table: USER B will be forced to wait until USER A either implicitly or
explicitly completes his Logical Unit of Work.  This happens if the NUMBER OF
LOCK REQUEST BLOCKS is set at the default of 1000.  SQL/DS will automatically
lock the entire DBSPACE, therefore locking all tables in that particular
DBSPACE.  The IBM SQL/DS manual suggests that you increase the NLRBU to
accommodate your needs.  This recommendation has two problems associated with
it:
1    Two lock request blocks are usually used for every lock that a user has.
In our example above, if locking is being performed on the row level, more than
400 rows are returned for each user and we have 10 users active, there are 800
lock request blocks active per user, bringing our total to 8000 lock requests in
the system.  Each lock request requires 24 bytes; thus our memory requirement
just to obtain the locks is 192 000 bytes!
2    You can only increase the NLRBU to a maximum of 588 333, so if you have a
large table, this approach will lead to bigger problems down the road as more
data and applications are set up under SQL/DS.
In order to rectify this situation you must first prove that it is occurring by
using the COUNTER * command in ISQL to determine the number of escalations.
The preferred solution is to review the request/application to determine if the
isolation can be set to Cursor Stability, instead of the default of Repeatable
Read.
Cursor Stability will help reduce the locking problem and virtual memory
requirements because SQL/DS does not hold the lock as long.  Once a cursor (a
cursor is a pointer that SQL/DS and DB2 uses to point to a row in the desired
table) has moved past a row or page of data, the lock on that data is
immediately dropped.  This increases concurrency and allows other users to
access data in the table.
BUFFER UTILISATION
SQL/DS uses mainly two sets of buffers to store pages that have been read from
the disk.
One set is used for the directory pages and one set for the data.  Experience
has shown that it is more important to have as many directory pages in the
buffer pool as possible (500+ is a good starting point).  This is because SQL/DS
uses the directory to supply physical DASD addresses for the data pages that are
read from disk.  This means the directory is involved in every data page read
and write operation.  A good example of this is when SQL/DS wants to insert a
row: it would have to scan the real pages of the DBSPACE in the STORAGE POOL to
find a page with enough free space to insert the row and continue to respect
free space requests.  To avoid this page scanning, SQL/DS will, in this case,
scan only the DIRECTORY pointer entries of the DBSPACE to find the data page
candidate for the insert.  This means getting free space information for 128
data pages with one directory I/O instead of one I/O for each individual page.
Great care must be taken when increasing the buffer pool requirement because the
DBA must take great care to prevent the SQL/DS virtual machine from paging at
all costs!  This is because all activity must be stopped while the paging
 request is being fulfilled.  On the other hand SQL/DS is designed to process
multiple tasks concurrently when it has to search for data in its buffers.
The directory buffers and page buffers are specified as start-up parameters for
SQL/DS.  The defaults can be changed to NDIRBUF=1000 and NPAGBUF=250.
DBASPACES
In order to have maximum performance each table containing more than 3000 rows
should be placed in a separate public DBSPACE with at least one index on a
column.  When the index is created, insertions operate more quickly if a free
space parameter of 40% or more is used.
APPLICATION DEVELOPMENT
COMMIT
The purpose of the COMMIT verb is to request SQL/DS (and DB2) to make permanent
the changes that have been made in the current logical unit of work in the
database.
The application developer should never be forced into issuing this verb before
it is necessary to do so, ie in a banking environment a COMMIT should be issued
when all transactions for a particular branch have been processed.  A common
mistake in SQL/DS (and DB2 shops) is to issue a COMMIT randomly, or for a
certain number of transactions, in order to free-up log space sooner.  This is a
problem because it will force the developer to add more logic in order to
recover from a failure, when SQL/DS (and DB2) have been designed to provide
recovery from failures automatically, thus resulting in reduced performance.
PUT
If your application wishes to insert data into a table you will get increased
performance by using a PUT instead of an INSERT.  The PUT instruction is more
efficient because it accumulates the data to be inserted in 8K buffers and then
'puts' the 8K chunk of data in the table in one smooth operation.
UPDATE
Remember, with the UPDATE command only update the columns that need to be
updated.  This means you do not have to 'Replace' the entire row when you change
data only for a specific number of columns (or fields).  The reason for this is
that when you specify that you wish to update a column that is used as in index
SQL/DS will not use the index to find the requested row(s); it will, however,
choose to scan all the rows in the table to satisfy the search condition
(predicate).
If you need to change the column of a table that is used as an index it is
better to use the delete/insert command in place of the SQL UPDATE command.
This will give better performance because SQL/DS will use the index to find the
requested data.
Morris Hoodye
President
Morris Computing Systems Inc (USA)      ) Xephon 1988
























