 Controlling CICS performance under VM/VSE
INTRODUCTION
During my former work as a contract systems programmer I found many VM/VSE shops
having problems with CICS performance.  VM is a very comprehensive operating
system and it contains many options that may control the performance of virtual
machines, especially multi-user guest operating systems such as VSE.
This article tries to give the reader an idea of the various options that exist
and how they function.  Special emphasis is given to the options that influence
CICS performance directly as CICS users are usually those who initially
experience the impact of a poorly performing system.
The first part contains a brief description of the options that affect the
performance of a virtual machine internally, ie with no influence on other
virtual machines.  These options may seem quite obvious to more experienced
system administrators, but not to all.
The options described in Part One apply to VM/SP as well as VM/HPO.  However,
the options in Part Two do not necessarily apply to VM/HPO as some of the
options have a different meaning in VM/HPO.  The information in this document is
based on VM/SP Release 4 but applies to other releases as well.  Users of VM/HPO
should consult the VM/HPO Tuning Guide, SC23-0404 as it contains a description
of the various options that specifically apply to VM/HPO.
PART ONE
These options may be given either on the OPTION directory statement or as a CP
command, eg in the PROFILE EXEC.  The options as given on the OPTION statement
follow.
The BMX option
This simulates the use of block multiplexor channels instead of selector
channels, which are the default.  It affects all virtual channels except channel
0, which is always a byte multiplexor channel.  Block multiplexing allows
simultaneous I/O requests to devices attached to the same virtual channel,
whereas selector channels only allow one I/O request to execute in the channel
at a time.  It is obvious that if your VSE virtual machine lacks this option, it
may severely degrade the performance of the I/O system.
The PAGEX option
Normally you need not be concerned about this option as the VSE supervisor
executes CP SET PAGEX ON during IPL (this option does not exist as an option on
the OPTION directory statement, but only as a CP command).  The effect of not
using this option is that virtual machine page faults are not reflected back to
the virtual machine.  It means that the whole virtual machine, and not only the
partition in which it occurred, is put into a wait state until the requested
page is brought into real storage.  An exception to this is ICCF under VSE/AF
Version 1, as ICCF issues CP SET PAGEX OFF during start-up.  Unfortunately this
is a necessity to make ICCF function properly in certain situations.  This
problem has been solved in part by VSE/SP 2.1 as ICCF no longer issues CP SET
PAGEX OFF during start-up.  The function is switched off only when necessary and
back on again afterwards.
The 370E option
This enables the virtual machine to make use of certain hardware performance
routines present on some CPUs.  This option should provide a slight improvement
in performance.  It is for VSE/SP 2.1 (and MVS) only and is of no use to pre-
VSE/SP releases.  These hardware routines should be present on all 303x and 308x
processors and some 43x1 processors.  You will be notified by a CP message if
these options are not present on the CPU when trying to use this option.
The AUTOPOLL option
If you are using CICS with BTAM you should use this option to reduce the
overhead involved when CP has to test whether BTAM CCWs have been dynamically
modified.  You should issue CP SET AUTOPOLL ON in your PROFILE EXEC during IPL.
This option does not exist as an option on the OPTION directory statement, but
only as a CP command.
PART TWO
This section contains the options that affect the performance of a virtual
machine at the expense of other virtual machines.
The PRIORITY option
To a shop that started with native VSE and later put VM on the top, priority may
seem the most obvious performance option.  However, this may not always be the
best way to control performance.  This is because of the nature of the VM fair-
share scheduler.  The scheduler calculates a so-called dead-line priority (not
 to be confused with the priority given in the directory, which is called user
priority) every time a virtual machine becomes undispatchable, ie waiting for
some event to occur.  This dead-line priority is based on virtual machine
resource consumption, global system load, time of day the virtual machine was
last dispatched, and the user priority.  What this means is that the virtual
machine having the highest user priority is not necessarily the first virtual
machine to be dispatched.  Likewise, no virtual machine can monopolise the CPU
because of highest priority alone.
Note that priority is specified from one to 99 with 64 as the default and the
lower the number the better the priority.
Generally a high-priority machine performs better than a lower priority virtual
machine, but as mentioned above user priority is not the only factor considered
when the scheduler decides which virtual machine to dispatch.  The following
options specifically address CPU and real storage usage and may be better
alternatives or supplements to control the performance of a given virtual
machine.
The FAVOR option
This option is used specifically to control CPU consumption.  FAVORing is
available in two variations, which may be used concurrently:  the basic FAVORED
option and the FAVORED execution percentage option.  The basic FAVORED option
(CP SET FAVORED user-id) enables a virtual machine to stay in the run list at
all times, ie the list of dispatchable machines.  The FAVORED execution
percentage option (CP SET FAVORED user-id nnn) specifies that a virtual machine
is to receive a given percentage of the CPU, if it can use it.
You may specify from one to 100 per cent, where 100 is a special case and means
that CP will always try to dispatch that machine first.  If a virtual machine
uses more than the specified percentage it will have to compete on an equal
basis with the other virtual machines.  Both variations may be specified for
multiple virtual machines and when using the percentage option the sum may
exceed 100 per cent but CP will then reduce the numbers proportionally.
FAVORing is the most precise means to control CPU consumption and is normally
better than priority.  You may use both FAVORing and PRIORITY together, but be
sure that you use FAVORing and good PRIORITY with the same virtual machine,
otherwise you can be almost certain that you will not obtain the desired result
as PRIORITY tends to take precedence over FAVORing.
The LOCK option
This specifies that one or more pages of virtual machine storage are to be fixed
in real storage.  You could, for example, use this option to LOCK selected parts
of the CICS nucleus in real storage to avoid these pages getting paged out.
However, this is not really flexible as it requires the knowledge of where the
CICS nucleus is located in virtual machine storage, and, furthermore, this may
change from time to time because of changes in CICS tables, partition size etc.
However, if you wish to use this option you should be aware that the supervisor
and your TP access method (ie BTAM or VTAM) should be taken into consideration
when deciding what to lock.  This option exists only as a CP command and may be
used for multiple virtual machines.
The RESERVE option
This RESERVEs a number of real storage page frames for a particular virtual
machine.  It acts as a private page pool to that virtual machine.  This is
normally a better alternative than LOCK because the most used pages
automatically tend to remain in real storage and you donUt have to be concerned
about addresses of heavily-used pages.  However, it does have its price since
the reserved pages are taken from the common page pool thereby reducing it (this
applies for LOCK too).  This may cause the other virtual machines to start
paging at an unacceptable rate.  It requires some testing to determine the
optimum number of pages to RESERVE.  If you have tools like VMMAP or SMART you
might get some help as both tools give you an average working set that may be a
good starting value.  The effect on paging is usually very dramatic.  I have
experienced one case where we had a system with a total page rate of 25 pages
per second, which was unacceptable in terms of CICS response time.  We decided
to RESERVE the average working set, which was about a third of the page pool, to
the virtual machine that ran our production CICS system.  As a result the total
page rate in the system went up to 60 pages per second, but CICS response time
(and the page rate of the particular machine) went down to about a half of what
it was before.  The impact on the other virtual machines was also amazing,
especially to the other virtual VSE machines whose CICS response times went up
to about 2 minutes (which was accepted at the time because good response time in
the production system was considered vital).  This option only exists as a CP
command and may be specified for multiple virtual machines.
The QDROP OFF option
Another approach to reducing paging for a particular virtual machine is Tqueue
dropU elimination.  This option inhibits CP putting the virtual machine pages on
the flush list when the virtual machine becomes inactive.  This is especially
important for CICS systems of low to medium activity that would otherwise be
paged out between periods of activity.  High activity CICS systems may also
benefit from this, as this option tends to keep a larger number of pages
resident in real storage and thereby reduces the possibility of page faults.
GENERAL HINTS
There are two ways of defining disk space to a virtual machine:
1    Define a disk as a MDISK in the directory
2    Define a disk as DEDICATED in the directory (or via CP ATTACH).
From a performance point of view DEDICATE is the best method as it reduces CP
overhead when translating CCWs.  However, dedicating a disk means that you
reserve a full disk volume for a virtual machine.  If that isnUt desirable or if
you wish to use DASD-sharing between multiple virtual VSE machines, you must use
the MDISK approach.
Try to keep your CICS DSA large in order to reduce program loads;  a CP paging
operation is cheaper than a CICS program load.  However, paging canUt replace
CICS program loads and of course paging must be kept to a moderate level; one to
two paging operations per second in a CICS system is normally acceptable.
Higher paging rates could cause performance problems.  Normally paging is
cheaper than any other type of I/O, unless the paging subsystem has become a
bottleneck in your system.
Place as many SVA-eligible CICS modules in the SVA as possible The reason for
this is two-fold:  it saves space when you have more than one CICS system
running in a virtual machine, and it reduces the risk of destroying the CICS
nucleus if you have a program that causes a storage violation, because modules
residing in the SVA execute under a different storage key.
Use VSAM Local Shared Resources as much as possible.  Many good articles on this
issue have been published in CICS Update.
Keep VSAM Control Intervals at 4K whenever possible, as 4K is also the page size
in CP.
This leads on to the question, RWhat is the optimum page size in CICS (ie the
PGSIZE parameter in DFHSIT)?S  You may choose between 2K, which is the size that
the native VSE system uses, and 4K, which CP uses.  2K pages will obviously
reduce fragmentation, ie the space on a page that is unusable because space is
allocated in pages.  4K seems to be optimum from a CP paging viewpoint.  I have
asked IBM Technical Support this question but they couldnUt give me a precise
answer.
EditorUs note: If any of our readers have experience in deciding which is the
better value to use for the PGSIZE parameter, we would very much like to hear
from them.

Steen Spuur Hansen
Systems Programmer
Texaco A/S (Denmark)     ) Xephon 1988
















