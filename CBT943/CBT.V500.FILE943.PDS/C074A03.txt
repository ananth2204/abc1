CICS tuning - avoiding physical I/O

You have probably read several articles about performance
issues on this subject advocating such strategies as
implementing LSR for VSAM files, increasing the number of
strings and buffers, using IMBED and REPLICATE at VSAM
cluster definition time, etc.  Other tuning possibilities for
VSAM files are provided through data spaces, hiperspaces, the
Data Tables feature (available from CICS 2.1.1), but what
about DL/I databases?  In the CICS start-up JCL you have the
//DFSVSAMP  DD statement, where you specify the buffers
(both size and number) for DL/I.  Which buffer sizes to specify
is not so difficult to find out (it depends on the CI sizes you
have specified at VSAM cluster definition time for your
databases) but the question is how many buffers?  (Of course,
these considerations are not applicable to CICS/ESA Version 3
environments, where a separate DL/I address space takes care
of the database accesses.)

It is not possible to specify a simple formula which lets you
calculate the optimum number of buffers you need for each
buffer size.  So what I suggest is a trial and error method: you
start with a certain number of buffers and adjust the numbers
according to the results.  You will notice here that I have made
a typical management decision - I have shifted the problem.
Now the question is: how do I measure the results?

Let us first make clear what we are after here.  In fact, we have
to deal with a mechanism similar to LSR for VSAM files.  We
expect a good percentage of (buffer) look-aside hits for our
DL/I calls (reducing the number of physical I/Os).  You might
now suggest allocating a very large number of buffers.  With
an increasing number of buffers the hit ratio will increase also,
but if we plot the curve we see it flattens and we end up with
an infinite number of buffers (see Figure 1).

The optimum range varies between a hit ratio of 70% to 80%.
You should not forget that a large number of buffers incurs
some negative aspects.  The DL/I buffer pool is allocated
below the 16-megabyte line and reduces the available virtual
storage for the program subpool: the frequency of program
compression will increase.  By allocating more buffers we also
increase the CICS Working Set Size and the number of pages
fixed in real storage.  Unless you have plenty of real storage,
the paging rate will increase also and CICS performance is very
sensitive to this.  Of course, you can protect CICS by
allocating a large Protected Working Set Size (PWSS).  CICS
will be very happy but other workloads will suffer from it.  I
apologise for getting into the area of MVS performance and
tuning considerations, but I think you will agree with me that
CICS performance cannot be isolated from MVS performance.
The more you know about MVS the better you will be able to
tune CICS.

Let us go back now to our problem of measurement of the hit
ratio (ie the number of successful look-asides for DL/I calls).
If you have a CICS monitor, it should provide you with the
desired information  (see Figure 2).


If you do not have a monitor (which would be a pity) refer to
Issue 5 of CICS Update (April 1986).  The program published
there can easily be adapted to run in different releases of CICS
(DOS and MVS).  Via an on-line transaction you can display
the desired information accumulated since the start-up of CICS
and when you put the program in the PLTSD (program list
table at shut down) it will print the end-of-day statistics (hit
ratios) as shown in Figure 3.


Note that you may run into a situation where after allocating a
large number of buffers (say, 80, 100, 125, etc) you still have
a poor hit ratio (only 20 to 30%, for example).  This probably
indicates an application design problem.  This could be a
transaction which performs about 1500 GET NEXT calls on a
database every time.  Under these circumstances, the whole
buffer pool will be refreshed before you get any chance to have
any look-aside hits.


Fran ois Mortier
Systems and Operations Manager
Atlas Copco Airpower NV (Belgium)

