The SHARE CICS performance tutorial


INTRODUCTION

With continually spiralling people costs and hardware costs
declining even more quickly, many installations choose to
ignore the optimization of performance of any component of a
computer system.  But it is precisely those high people costs
that dictate the necessity of tuning a heavily used OLTP like
CICS:  every second shaved off transaction response time
quickly adds up to savings of multiple man-years each year,
when the number of transactions and users is multiplied by
those seconds saved.

Even if response time is not an issue, a neglected CICS system
can easily get so far out of hand that performance tuning turns
into problem determination in a crisis management
environment.  Even if things are fairly much in hand, reducing
the hardware resources required for a given unit of CICS work
can:

o      Reduce hardware needs

o      Provide for future expansion

o      Allow allocation of resources to other uses.

Any way you look at it, a small saving in hardware, say 1
percent, could easily save several hundred thousands of any
currency.  In fact, tuning can mean job security.  Reducing the
response time and costs associated with existing CICS
transactions makes mini- and micro-based alternatives much
less appealing.

Tom Harper  of BMC Software has given his CICS
performance tutorial session for more than ten years, at twenty-
one consecutive SHARE major meetings.  Exploiting three
back-to-back one hour sessions to their limit, Tom covers an
enormous amount of valuable material for the CICS tuning
specialist.  I was fortunate enough to attend all three sessions at
a recent SHARE.  What follows is a consolidation of his
formal paper from the 35th Anniversary SHARE proceedings,
his handout for the sessions, and my own notes from the
preceding SHARE.

The focus is on an environment consisting of CICS 1.7, CICS
2.1, or CICS 3.1.1; VTAM; and VSAM -  DBMSs are not
specifically dealt with.  Because SHARE does not cover VSE
and the use of CICS in VM is low, Tom's presentation focuses
on MVS.  However, with a little translation there is a lot of
excellent information for all CICS environments.

Personally, what I found refreshing about Tom's approach is
that he does not focus on CICS alone, but looks at all the
factors that effect CICS performance.


GATHERING INFORMATION

Tuning often does more harm than good when it is based on
insufficient or improperly analysed information.  To measure
the status quo, four tools are necessary.  CICS Auxiliary Trace
(AUXTRACE) is nobody's interpretation of the facts.  It shows
you what is really going on.  As such, it is the best single
diagnostic tool for analysing internal response.  Perhaps the
easiest to use tool, but the most frequently overlooked, CICS
statistics provide some useful information, despite their
crudity.  Access Method Services (IDCAMS) provides basic
information about the VSAM datasets used by CICS.  The
operating system also influences the performance of CICS.
The Resource Measurement Facility (RMFMON) focuses on
how well MVS is dealing with CICS.

AUXTRACE

Run it for ten to fifteen minutes in an hour when response time
is known to be poor.  Since 90 percent of the internal response
time consists of waits, focus on eliminating or reducing
transaction waits, especially storage, program loads, maximum
task (MXT, CMXT, AMXT), file I/O, transient data queues,
temporary storage queues, and enqueues.  To be sure that you
are not measuring the measurement tool instead of user
transactions, any performance problems noted with
AUXTRACE itself can be resolved by adding buffers and/or
zapping the block size of its DCB.

CICS statistics

Look at Short On Storage (SOS), MXT, CMXT, AMXT, PPT
program loads, PCT transactions at CLASS MAX tasks,
VSAM shared resources look-asides, FCT string waits,
temporary storage and transient data I/O, and journal control
waits.

RMFMON

Look at the CPU dispatching priority (DP PR), real storage
frames in use (RSF), demand paging rates (DPR), unreferenced
interval counter (UIC), page delay time (PDT), target working
set sizes (WSS), SRM, channel activity, and device and unit
contention.

IDCAMS

Look at the number of extents, CI and CA size, splits and free
space, EXCPs for data and index components, share options,
and read/update ratio.  Figures from IDCAMS for splits and
EXCPs are often inaccurate because these figures are only
updated when VSAM files are closed normally.  With the trend
toward continuous operation, CICS probably crashes more
often than it is brought down properly, and VSAM files do not
get closed properly.  One solution is to close and open all files
every two to three hours.  Non-IBM products exist to view this
information on-line.  For splits, SMF is the most accurate tool.
It can even be used to plot the number of splits against the time
of day.


IMPROVING RESPONSE TIMES

The assumption is made that there is some sort of response
time measurement already in place.  The only reliable methods
are a stop watch or the Response Time Monitor (RTM) to
keyboard unlock, not first character displayed.  Other methods
(eg the CICSPARS definite response method) either ignore or
do not actually measure the data communications component of
response time.

Armed with this information, there are six things you can do,
and they make up the six sections that follow.

1.  Change priority

Change the priority of the requestor.  "CICS generally uses
little CPU and will get in and out of the system quickly."
Therefore, Tom recommends giving all production CICS
systems the same high dispatching priority by having them
share a single Automatic Priority Group (APG).  Using MVS
Performance Groups, Tom suggests that the system priorities
should be:
1      Master Scheduler
2      VTAM
3      CICS
4      JES2/3
5      TSO
6      Batch
7      IMS.

To allow intervention during a CICS loop, a single TSO user-id
should be defined with a priority above CICS, to be used only
in such emergencies.

On the other hand, CICS internal priorities are best left
untouched.  Favouring particular terminals, transactions, or
operator-ids will increase real storage requirements - a poor
trade-off since CPU time is such a small component of
response time.

2.  Exclude other users

Exclude other users from the resource.  Storage isolation,
through the MVS System Resource Manager (SRM), can
guarantee that CICS gets the real storage it needs.  Give CICS
too little and performance degrades quickly.  Give CICS too
much and other address spaces experience high paging rates
and poor performance.  Obviously, this approach is irrelevant
to dedicated CICS systems.

Since CICS real storage requirements vary based on work load,
SRM can be instructed to adjust the amount of real storage
CICS is allocated using the following algorithm:

o      Given a Target Working Set Size (TWSS), reserve this
      many page frames of real storage for CICS.

o      If more real storage is needed, give CICS priority in page
stealing.

o      Periodically adjust TWSS, 7 percent higher if the CICS
      paging rate reaches one threshold, 3 percent lower if it falls
      below another.

Before proceeding further, use RMFMON to determine the
Page Delay Time (PDT) in CICS.  Anything over 100
milliseconds indicates a severe problem with the paging
subsystem.  Either fix it or plan to never let CICS page.  A
PDT of 60 milliseconds is normal - 20 milliseconds is
excellent.

During normal (not peak) load, when CICS is performing
adequately and providing the desired response time, determine
the number of real storage frames used by CICS by examining
RSF in RMFMON.  Code the SRM parameter PWSS to the
minimum and maximum performance working set sizes:  one
third less and one third more.

For example, if RSF is 666, then PWSS should be set to
(444,888).  This is the range in which SRM will tune the
number of page frames of real storage (TWSS) assigned to
CICS.

Next, set the minimum and maximum performance page-in rate
limits.  PPGRT uses CPU time as the clock while PPGRTR
uses elapsed time.  For good response time under peak loads,
set the minimum to 1 percent of RSF and the maximum to 2
percent.  For excellent response, set to 0.5 percent and 1
percent.

In the above example, PPGRTR=(7,13) and PPGRTR=(3,7)
should be used.  These values should be considered a starting
point for further tuning based on the response time
experienced.

Equivalent SRM parameters also exist for the common area:
CSA, SQA, and PLPA.  Tom recommends using
CWSS=(1000,2000) and CPGRT=(5,20) as a starting point for
experimentation.

Beyond SRM, there are four ways to isolate CICS from other
address spaces:

1      Move TSO, IMS, and batch workloads to other systems.
      PR/SM logical partitions are an acceptable alternative to
      separate stand-alone systems.

2      Eliminate shared DASD and reserve problems.

3      Isolate all datasets/databases, program load libraries, and
      operating system datasets used by CICS from use by other
      address spaces.  Dedicated channels and volumes should
      be used for these datasets.  And they should be contiguous
      - no multiple extents:  each VSAM data component should
      be adjacent to its index component.

4      Isolate the paging subsystem's channels and devices from
      heavily-used datasets or use solid state paging devices.

CICS and IMS do not co-exist well together.  CICS requires a
large private area and a small common area, IMS requires a
small private and a large common area.

Seemingly innocent operations can hurt performance.  A
simple REPRO, used for test loads, puts a reserve on a
volume, locking out any production CICS datasets on the same
volume.

3.  Shift request

Shift the request from one resource to another.  Because they
extend the transaction's life, reducing VSAM/VTAM buffers,
reducing the number of resident programs, and making
temporary storage auxiliary does not reduce real memory
usage.  Instead, concentrate on reducing the number of
concurrent tasks through MXT, CMXT, and AMXT.  It may
actually increase throughput.  Of the three, AMXT is the
parameter of choice to change.  However, if only one
transaction is a problem, CMXT may be a better choice.

VSAM Local Shared Resources (LSR) can provide better
buffering, but deadlocks can occur on transactions that ran
successfully under NSR.  To avoid this problem, all files in all
CICS test systems should be defined with one string to ensure
that string locks do not occur when the application goes into
production.  Because it reduces file I/O by 50 to 90 percent,
VSAM LSR can also reduce channel and device time.  Two to
four hundred buffers dedicated to LSR will maximize its
effectiveness.  Use VSAM mass insert and generic delete.

Calculate the ratio of use count to program size for each
program and make the programs with the highest ratios
resident.  The exception to this rule is CICS/ESA, which
automatically unloads the least recently used programs.  This
would seem to dictate that no programs should be made
resident.

AMP='BUFNI=n' in JCL may be the easiest way to get the
indexes for each VSAM dataset in memory.  The statistics for
the index component of a KSDS dataset from the IDCAMS
LISTCAT command indicate the number of index levels.  Add
this number to the number of strings defined for the dataset to
determine the number of index buffers required for peak
performance.

Imbedding the sequence set (VSAM's lowest level index)
places it in the same cylinder as the data control interval (CI)
that it indexes, eliminating DASD head movement.  CI and CA
splits can be avoided by increasing the free space percentages.
Use the data tables feature of CICS Versions 2 and 3 to replace
small, heavily-used, read-only files.  In CICS 1.7, they can be
converted to tables stored as resident load modules.

Next, tune the network.  Whenever possible, change half
duplex lines to full duplex and multi-drop lines to dedicated
lines.  A full duplex, dedicated line eliminates the delay
associated with line turnarounds.  A full duplex, multi-drop
line allows sending to one 3270 while simultaneously receiving
from another.  A multi-drop line where any line-attached
device (3x74, 3276, PC with SNA card, etc) may be turned off
can see a dramatic improvement in response by setting
SERVLIM to a high number (eg 60).  Otherwise, there will be
frequent 5 to 10 second stalls while the NCP is waiting for a
response from the dead device.  The only negative effect of a
high SERVLIM value will be a delay in activating the device
once it is turned back on.

In the TCT, BUFFER should be 1536 for display terminals and
256 for printers.  These numbers become the outbound RU size
for VTAM.  RUSIZE specifies the inbound RU size and should
be 256.  If there are fewer than forty data streams inbound per
second, DELAY and PAUSE should be set to zero in the NCP
generation.  Otherwise, a value of 0.2 seconds for each would
be a good place to start.  MAXDATA should be set as large as
possible and except for noisy lines (ie lines with lots of errors),
MAXOUT should be 7 for a 3270, allowing up to seven frames
to be sent before an acknowledgement is received.  An
exception to this is satellite links, whose long delays would
benefit from a value of 63.

If all data streams are about the same length, a high value for
PASSLIM is recommended.  If data stream sizes vary widely,
PASSLIM should be set low.  IBM's TPNS can be used to test
the effect of this and other network parameters.  Watch out for
statistical multiplexors, as they can introduce significant delays
due to buffering when lines are in heavy use.

Multi-Region Operation (MRO) can exploit multiple CPU
systems, overlap I/O operations, reduce DFHRPL contention,
and provide faster restarts.  Turning off trace will answer most
of the horror stories you may have heard about MRO overhead.
MRO operations create a lot of trace entries:  trace adds 20 to
25 percent overhead to an MRO environment, but only 10
percent to a non-MRO environment.  Faster restarts come from
the overlapping of opens when CICS is split into three regions:
terminal-owning, transaction-owning, and file-owning.
Performance benefits can also be obtained by placing high
volume applications in their own region.  CICS will not be able
to use cross memory services to communicate efficiently
between MRO regions unless ACCMETH=(IRC,XM) is
specified in the system TCT.

Auxiliary temporary storage can benefit from more buffers,
specified in the SIT.  Three is the default, but 10 to 20 is the
recommended minimum, and 50 to 100 would improve
performance substantially, assuming below-the-line virtual
memory is available.  Other factors that will help include:

o      A CI size of at least 4K.
o      Avoid spanning CIs.
o      Specify exactly one string (in the SIT) per access arm.
      This is the only number that eliminates operating system
queueing.

"Multiple volumes for temporary storage is an excellent idea, if
your I/O rate to the temporary storage dataset is high and you
are unable to afford additional buffers or your temporary
storage is recoverable.  When allocating the dataset, remember
that most of the activity takes place on the low-numbered CIs.
In order to spread the I/O activity around, make the allocation
on the first volume small (eg one cylinder).  This will force
more activity to the next volume.  Do not over-allocate the
temporary storage dataset.  One byte of below-the-line storage
is used in CICS for each CI in the dataset."

Very heavily used VSAM files can be spread across multiple
DASD using the KEYRANGES attribute.

4.  Use less

Use less of a resource, such as real memory.  Remove unused
features (eg TCAM) and unused CICS table entries.  Program
packing occurs when NLT and ALT, not PPT, are used to
specify which programs should be resident.  Set the CICS page
size to 2K (1K for CICS 3.x) to reduce wasted space between
programs.

The PLPA allows the sharing of programs used in CICS
between multiple CICS regions or between batch and CICS and
can be used for the following:

o      CICS management modules - 140K of real storage.

o      Most other CICS programs are PLPA-eligible.

o      Re-entrant application programs.

o      IBM-supplied COBOL subroutines - use the RESIDENT
      compile option (DYNAM will also work for batch
programs)

o      IBM-supplied PL/I subroutines - use the PL/I Shared
      Library option.

Running CICS as a started task, not a batch job, eliminates
initiator/terminator virtual storage.  VTAM automatic install
will decrease the virtual storage used by inactive TCTTE
entries.

Do not use anticipatory paging.  At best it provides no
performance benefit - in some installations it has been shown
to degrade performance.

To use less CPU time, generate BMS with the minimum
function necessary for your system.

In VTAM, a value of two for RAPOOL should be sufficient,
one if you do not use LU6.2 (IBM currently requires two for
LU6.2, but this may be reduced to one in the future).

Files should be allocated on cylinder boundaries to reduce DEB
checking.

Turn off the trace and save 10 to 12 percent (more if you use
MRO).  Turn off the CICS Monitoring Facility (CMF).

Use main temporary storage to eliminate the CPU time
associated with I/O with auxiliary temporary storage.  In
MVS/XA and MVS/ESA environments, main temporary
storage is stored above the 16-megabyte line.

Since a single EXCP to disk takes 7,000 instructions to
execute, any way of eliminating disk I/O should be explored.
Making programs resident is one way - command-level
programs can be above the line.

Using the CICS High Performance Option (HPO) provides
VTAM fast path execution and gives pseudo-conversational
terminal tasks primed storage.

Set IOCP in the SIT to the percentage of I/Os to complete so
that CICS will be dispatched less frequently and made to do
more work each time.

Do not use STGCHK=FAQE in your SIT.  Before CICS
Version 3, FLENGTH GETMAINs larger than 4K invoked
MVS GETMAIN with its high CPU time overhead and wasted
partial page frames.

To use less channel and device time, any data CI size greater
than 4K is a cause for investigation, since VSAM will never
actually use a physical block larger than 4K.  In fact, most
VSAM files would benefit from a smaller CI size.  The
exception would be those used sequentially (browsed files).
Application programs link-edited with the second parameter of
SIZE set to twice the library block size will be full-track
blocked.

CICS 1.7 was shipped with a sample, not a dummy, NEP.  The
conditional load of DFHNET will cause a BLDL for the entire
DFHRPL library for every log-on, log-off, and terminal error.
Either install a dummy NEP or write your own.  One major
way to reduce the terminal network load is to convert from
BSC to SDLC.  Queue time is reduced by making effective
data stream lengths shorter.

Hitting limit conditions is expensive.  Any limit condition hit
more than 5 percent of the time indicates the underlying cause
must be addressed or the limited condition changed.  Hitting
the turn-around point (TAP) means CICS must reload all the
purged programs.  Hitting it more than every ten minutes calls
for an increase in the virtual storage allocated to CICS.
Likewise, Short On Storage (SOS) means more virtual storage
should be allocated to CICS.  Virtual storage constraint is the
only excuse for ever going SOS.  TSGI extensions default to
four - too low for many systems.

At the other end of the scale, less than one string wait per file
every one to four hours calls for a reduction in strings allocated
in the FCT.

If CICS has to fail, have it fail fast.  Use SYSMDUMP - it is
faster, but it requires more OSCORE.  Have two dump datasets
and print dumps after restart.

MVS/ESA installations should run CICS/ESA (Version 3.x).
With it, SDUMP has MVS/ESA copy the entire address space
to a spare address space and leaves the writing of the dump
dataset to DASD for later.  In addition, CICS/ESA provides
much faster program loads and extended DSA.

5.  Buy more

Obtain more resources.

6.  Exploit unused resources

Exploit previously unused resources.  For a system with more
than one CPU - some 3090s and System/390s have six -
VSAM sub-tasking is a feature that gets another CPU to handle
VSAM I/O, including FCT, temporary storage, transient data,
and journal control.  Elapsed time decreases and CPU time and
real storage increase.  It cannot be used with IOCP and runs
poorly unless DFHPXR is in LPA.

If virtual storage constraint is a problem, but real storage is
not, make the RPL library VIO (virtual I/O provides scratch
files in virtual memory).  CICS/ESA users have a better
alternative:  VLA.  Copy modules in the VIO library at CICS
start-up time and include the VIO library in the RPL
concatenation.  To make NEWCOPY work, an empty library
can be created that is the first in the RPL concatenation.

As well as the many IBM manuals on the subject, Tom
recommends INFO/MVS or its equivalent through IBMLink:
fast path SRCH in the US and Canada.  It holds a wealth of
information that can often only be discovered by wading
through IBM source code, which is becoming less and less
available with the OCO policy.  Personally, I have found Jay
Ranade's VSAM Performance, Design, and Fine Tuning very
helpful in optimizing VSAM performance under CICS.  It is
widely available - I bought mine at a medium-sized bookstore
in London, England!

If you would like a more complete version of Tom's
presentation, find a recent copy of the SHARE Proceedings for
a major meeting.  Being a featured speaker, the paper is in
Volume 1, printed, not on microfiche.

Jon E Pearkins
Certified Software Specialists Ltd (Canada)

