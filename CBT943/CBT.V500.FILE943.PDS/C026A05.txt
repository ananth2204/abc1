 CICS tuning parameters
The main objectives of a systems programmer for an on-line CICS system should be
to provide the companyUs users with a stable CICS environment and maximum up-
time during prime working hours.  Additionally, adequate response times are a
must.
The definition of adequate response time can often vary greatly from one company
to the next.  With some companies an average response time of one second or less
is expected, while with other companies an average time of 5 to 10 seconds is
accepted as normal.
A recent study put out by IBM entitled The Economic Value of Response Time shows
that each second of system response time degradation leads to a similar
degradation of usersU total output.  One study indicated that with a response
time of three seconds a user could execute approximately 180 transactions per
hour, but when response time was reduced to 0.5 seconds, the user executed 370
transactions per hour or about a 105% increase.  Thus a reduction in response
time of 2.5 seconds saves 10 seconds of user time.  With todayUs emphasis on
productivity, a few seconds can have a sizeable impact on corporate
productivity.  I highly recommend that if you do not already have a copy of this
study done by IBM you obtain a copy and show it to your management.
With the value of rapid response time established, the next question is what do
we do to get response times hopefully into the sub-second range.  The theory in
many companies is to Tbuy a bigger machineU.  This may be the only alternative
in some cases but it may be totally unnecessary.
There are many factors that must be considered in establishing a well-tuned CICS
system.  Believe it or not, it is possible on an IBM 4341 Model 1 with 4MB and
nine other partitions running on a VSE system to service approximately 150
terminals and achieve an average response time of less than one second (it has
been done).
We have, however, migrated from the IBM 4341 to an IBM 3083 and now service over
165 terminals and over 150 applications.  We still run VSE Release 1.3.5 and
CICS 1.6, and our present response time average for about 100 000 transactions a
day is 0.500 sec.
To accomplish the above, we analysed and tuned a large number of individual
items.  I have broken these items down into four main categories and in each
category I have listed the items in order of decreasing influence on
performance.
The categories are: CICS parameters, systems parameters and programming
techniques, database and file tuning, and hardware and monitoring techniques.
CICS PARAMETERS
Very high impact
1    For terminals that are located in a remote location, the terminal I/O area
should be compressed before sending it over the Uphone line.  This by itself can
cut response time to a remote location in half.  There are several good packages
on the market that will do this compression, or you can write your own.
2    VSAM buffers and strings are very important to CICS response time.  Watch
the shut-down statistics or if you have a monitor, check the waiting for string
statistics regularly.  Files that are frequently waiting on strings should have
the STRNO parameter in the FCT increased until the condition goes away.  The
best way to tune this is by trial and error.  Just keep reducing the number of
strings by one until a problem occurs and then go back up by one or two strings.
     Data buffers should be allocated by using the simple formula of two times
the number of strings plus one or two extra depending on the file volume.
     Index buffers should be one per index level times the number of strings.
Note that the defaults that IBM provides usually leave you short of buffers
which can adversely affect response time.
High impact
1    When generating the TCT for local CRTs, the GPENTRY macro will default to
one line for every 32 devices.  This means there is only one ECB for 32 users.
This could be a bottleneck in a heavily-loaded system because CICS waits for the
I/O to be completed before accepting requests from other ports.  A good rule of
thumb to follow would be to allow for approximately 350 transactions per hour
per logical line.  A good monitor that will provide batch statistics by terminal
will help in obtaining these statistics.  We settled on eight CRTs per logical
line for our system.
2    Make as many programs resident as possible.  Again use shut-down or monitor
statistics to determine which are the highly-used programs.  A shop can actually
 experience a gain in virtual storage by doing this because fetched programs are
page aligned while resident programs are loaded concurrently.
3    When setting up line groups and TCT entries, make sure that printers are
not just placed anywhere in the line group.  If there were ten terminals in a
line group and the fourth one was a printer, the last six terminals could
experience erratic response times.  Always place printers last in a line group
or, better yet, put each one in a line group by itself for best response time.
4    Be careful when setting up maps in the PPT.  If USAGE=MAP and RES=NO are
specified, the map will be loaded each time it is used.  Specify RES=YES for
best performance or donUt specify USAGE=MAP.  By not specifying USAGE=MAP, the
map will remain in the program subpool at least until the space is needed for
another phase.
5    Be careful of software packages or your own routines that communicate with
POWER using PUTSPOOL and CTLSPOOL commands.  Most of them put CICS into a
partition wait.  There are better ways to perform POWER communication.
6    Watch shut-down or monitor statistics for program compressions.  Each time
CICS runs short on storage it must search the PPT to find temporarily resident
programs and maps and purge them from core.  When this is done, CICS gets back
to servicing users and several times there are many program loads done.
Anything over four compressions per hour should require some checking.
7    Watch for storage violations.  Even if they donUt bring down the system, it
does take CICS time to recover.  Note that if a storage violation occurred
against a terminal, the violation occurred in the TIOA, while if it is logged
against a transaction, it occurred in transaction storage.
Medium impact
1    For DOS systems, set the ICVSWT (DOS short wait time) in the SIT equal to
the average disk service time for the devices used:
     %    3340s = 40
     %    3350s = 30
     %    3370s = 25
     %    3375s = 30
     %    3380s = 25.
2    Increase the TMSGSET parameter in the SIT until the number of extensions in
the CICS shut-down statistics are less than 20, or until the maximum value for
TMSGSET is reached.
3    For those who purchase a lot of software packages, beware of certain
transactions that cause CICS to do a short wait.  They will result in erratic
response times.
4    The INAREAL parameter in the TCT should be made large enough to handle the
majority of the input buffers to be received.  The manual says to make this the
average size, but there is only one TCP and if a larger message comes in
additional storage must be acquired to handle it.  Everyone else waits while
this is being done.
5    The AMXT parameter should be set high enough so that it is not normally
reached.  For DOS systems somewhere between 15 and 25 would be a normal figure.
Low impact
1    Make sure the ICV parameter in the SIT is set to 0001000 (1.0 second) or
less.  This parameter controls the maximum time CICS will allow for batch
programs.  The lower the value, the less chance there will be for CICS to be
paged out.
2    If the PPT has over 300 entries, it should be indexed.  This speeds up
search time and allows CICS to dispatch more quickly.  Also put all of the
highest-used programs at the top of the PPT.  This will allow them to be kept in
core and the least-used entries will be paged out.  One exception to the above
are programs with corresponding entries in the PCT; they should be at the bottom
of the PPT and in reverse order by usage (low to high).
3    Although datastream compression on local terminals is not worth the CPU
time to do it, that is not true of local printers.  As with remote terminals,
local printers should have their datastreams compressed for best performance.
4    When using BTAM for remote line control, make sure that they are set up for
AUTOWRAP/OPEN poll.  This removes some of the polling burden from the CPU.
5    Once CICS has stabilised, turn off trace and auxiliary trace.  This saves
CPU overhead.  However, if a dump occurs, the trace area will not be available.
6    Increase the DBUFSZ parameter in the SIT until overflows to auxiliary
storage are nearly eliminated.  However, do not exceed 4K when doing this as
that seems to be the cut-off point for any performance benefits.
 7    If several remote printers are at the same location, multi-dropping them
will reduce control unit busy.
8    If using PAII for monitoring, make sure it has a large blocksize.  PAII
performs DOS waits and not task control waits.
9    Whenever possible use shared resources for VSAM files, especially those
with low usage.  This will save virtual storage (specify SHARE as an option on
the SERVREQ parameter).
SYSTEM PARAMETERS AND PROGRAMMING TECHNIQUES
Very high impact
1    If using VSE, one of its biggest drawbacks for performance is the fact that
it has only one Logical Transient Area (LTA).  This means that if a batch
partition has the LTA tied up, everyone else will wait until it is freed.  We
found a package called FAQS/FTL from Goal Systems, which provides multiple areas
as well as some other nice features and totally eliminates this problem.
2    If running under VM, the CICS partition can be page-fixed.  This alone can
greatly reduce response times.
High impact
1    If running on an IBM 4341, make sure that the supervisor has been generated
in ECPS mode.  This eliminates I/O overhead by as much as 15%.
2    If at all possible, donUt use CICS recovery/restart procedures.  Design
applications so that file updates are done on a record for record basis whenever
possible.  In other words, users shouldnUt enter 20 items before the program
does any processing.  By designing your program so that they are user-
restartable in the event of a crash, users can check their own records and pick
up where they left off.  This avoids a lot of overhead in journalling and
restarting.
3    When using the CICS journal feature, do not specify TWAITU as an option.
This causes the transaction to stop until the journal write has completed, and
if a number of transactions are all journalling, there will be a lot of time
spent waiting on the journal.  This could be as much as 60% of an individual
transactionUs response time.  If you must specify WAIT, set up a separate
journal for those transactions.
Medium impact
1    When setting up partitions, make sure that enough real storage (ALLOCR
command) is given to the CICS partition.  This will result in less paging for
CICS.
2    If paging is very high (above 5 pages per second), split up the page
dataset so that the CICS partition and the SVA are next to each other.  This
will eliminate arm movement and save paging wait time.
3    Always specify TRKHLD=NO in the supervisor if at all possible.
4    Set TPBAL=ON in your system start-up.
5    Two DOS supervisor options that cause a lot of overhead and little benefit
are DASDFP and FASTTR.  Both should be specified as NO.
6    Use the PRTY command to ensure that the CICS partition is always given
preferential treatment above batch partitions.
7    Design applications to do as few I/Os as possible.  Try to keep I/Os under
six per transaction whenever possible.  Avoid doing on-line searches to
summarise data whenever possible.  Use DELAY or SUSPEND on long running or high
I/O transactions to ensure everyone else gets their share of resources.
Low impact
1    Eliminate extra supervisor options.  Examples would be:
     %    CBF=NO
     %    NTASKS or NPARTS - specify no more than acutally used
     %    JA=YES instead of JA=(n1,n2.....nm).
2    Check copy blocks and channel queue entries making sure there are plenty.
Erratic response times could result if too few are present.
3    CICS must wait each time a phase is loaded from the core image library.
Remember there is only one PTA for loading phases and it is single threaded.
Use SLD and PSLD to reduce directory search time and make as many modules
resident as possible.
4    Try not to switch the dump dataset during prime time because it causes an
open/close, which makes CICS wait.
5    Keep program segments to a size of 4K or less whenever possible.  Keeping
program segments small will reduce paging.


 6    Code highly-used CICS programs in Assembler language.  Assembler is more
efficient than COBOL or PL/I and results in smaller modules.  This could mean up
to a 10% reduction in response times on some systems.
7    Avoid conversational tasks as they tend to chew up lots of virtual storage.
8    To avoid what is commonly termed Ta deadly embraceU, where two programs are
wanting the same resource, always, after a read for update, do a re-write or
unlock before going on to access a second file for update in the same program.
DATABASE AND FILE TUNING
Very high impact
1    Whenever possible do not use CICS disk temporary storage.  Temporary
storage has only one VSAM string and, if heavily used, can be the largest single
bottleneck in your CICS system.  It could account for 20% or more of your taskUs
wait times.  Whenever possible use main storage as it is not single threaded,
but when it is necessary to use disk temporary storage, set the CI size to 4K or
greater; also, it will help to make DBUFSZ larger.  Another thing that will help
is to place the file on a disk drive with little use, so arm contention will be
minimal.
2    VSAM files should always be specified as blocked in the FCT.  This will
ensure that the index and data buffers wonUt be released after each I/O request
(which is what will happen if they are specified as unblocked).  On a three-
level index, this will save three I/Os when getting the next record in the file.
3    Stay away from processing that uses the SETL / GETNEXT / ESETL approach.
Each time this cycle is completed, all of the VSAM buffers are purged.  An
alternative to this would be to set up DFHFC TYPE=GET with a Tgreater thanU or
Tequal toU type operation.  If the ESETL type processing must be done several
times for more than one file within the same transaction, consider using RSETL,
as it positions the file only and does not purge the buffers.
4    Stay away from VSAM SHAREOPTION 4 if at all possible.  This option purges
all VSAM buffers and forces a write after each request.  It also causes I/O to
the DOS lock file to record the enqueued Control Interval.  If you can control
or eliminate batch updates to the files being used under CICS, then I/O overhead
can be cut by 50% or more.  File response time can be greatly improved by not
using it.  The one advantage, however, to using SHAREOPTION 4 is that it can
simplify recovery/restart processing because each user and transaction can be
assured that only the record they were actually working on might not have been
updated.
High impact
1    Watch VSAM files for CI/CA splits.  When a CA split occurs, the entire
partition goes to sleep until the split is complete.  This can result in
somewhat erratic response times.  We tested 10 000 transactions for response
times and found the following effect:
       No split     CI split     CA split
         0.423        0.901        3.017
     As can be seen, splits can drastically affect response times, so whatever
can be done to eliminate or reduce them will benefit overall response times.
2    Avoid using VSAM KSDS files as scratch pad-type files to accumulate data
that will later be processed in batch.  The reason for this is because most
records added will result in a VSAM split.
3    VSAM clusters of more than one or two cylinders should always be allocated
in cylinders.  This will ensure that each CA is cylinder aligned and will keep
the number of index records to a minimum.
4    Always choose VSAM as a file access method over ISAM or DAM, because it
supports multiple string access.  ISAM files that are heavily used can slow down
an application by 50% or more.
Medium impact
1    Intrapartition and extrapartition datasets can cause bottlenecks as again
they only have one string available for processing.  This is especially true in
a heavily-used application.  Double buffering and a large CI size can help, but
a better alternative is an ESDS re-usable dataset with mass insert.  Using mass
insert you can do several thousand writes with only four actual I/Os.  Another
alternative would be a user journal with the ASIS option.
2    Watch shut-down statistics on temporary storage compressions and
suspensions.  If this is happening, more space must be given to the VSAM dataset
or more main storage given to temporary storage.


 3    Use a CI size of 4K or greater for CICS journal files.  This will prevent
unnecessary Twaiting on journalU if a buffer fills up.  Look at the buffer full
statistics at shut-down time for this information.
4    Always set up journals with the SYSWAIT parameter equal to ASIS to allow
overlapping of I/Os.
5    A CICS and batch monitor is almost a must so that file usage can be
analysed for activity.  Too much activity could result in a contention problem
and performance can be improved quite a bit simply by moving files around.
Low impact
1    Avoid opening and closing datasets during prime time as this puts CICS to
sleep.
2    Set up a separate core image library for CICS programs.  As this library
will be much smaller than a normal core image library, it will greatly reduce
directory search time when fetching CICS programs that are not resident.
3    DonUt place both journal TAU and journal TBU on the same disk drive.  When
a journal switch occurs, this will save contention especially if the other area
is going to be backed up to tape.  Furthermore, a journal switch also causes
CICS to go to sleep so it is best to schedule the switch outside peak hours.
4    For VSAM files using the shared resources option, standardise the Control
Interval sizes as this will use the buffer space and virtual storage available
most economically.  In the case of two files, one with a 4K Control Interval and
the other with a 1K Control Interval, there would be 3K wasted when the second
file is accessed.
5    Set up Control Interval sizes based on the type of access to be done to the
file.  If the file has a lot of sequential access, a large Control Interval size
will be of most benefit, whereas a file that is always accessed randomly will
benefit more from a small Control Interval size.  Again we ran tests with the
following results (average per thousand I/Os):
       CI size      Random response      Sequential response
         2048            0.162     0.233
         4096            0.181     0.174
         8192            0.193     0.141
HARDWARE AND MONITORING TECHNIQUES
Very high impact
1    A monitor is almost a must to assist in keeping a well-tuned system.  There
are at least five monitors available in todayUs market-place.  We feel two of
the best are THE MONITOR by Landmark Systems and OMEGAMON by Candle Corporation.
Each of these has a different approach and it would be advisable to use both if
possible.
     THE MONITOR provides on-line and batch analysis and is excellent for
tracking down and locating problem transactions easily.  Transactions can be
summarised in batch, if desired for long range statistics.  It is also useful in
locating file problems.
     OMEGAMON is excellent for on-line performance monitoring and can overview
the whole system, individual transactions, or groups of transactions.  It can
identify bottlenecks for each transaction and help identify what needs change.
It is ineffective, however, for long-range planning and cannot go back to five
minutes ago to analyse a problem.
2    One of the best investments that we made that has both helped cut down on
development time and improve up-time was a package by On-line Software called
INTERTEST.  This package selectively monitors programs and intercepts and stops
the execution of instructions that may have caused CICS to come down.  This
could be something as simple as adding into an initialised field or addressing
storage not belonging to your program.  Programmers can debug programs more
quickly and, by monitoring programs (both new and changed) that are put into the
production CICS partition, problems missed in testing will be caught before
damaging CICS.
High impact
1    DonUt use RPS - it causes extra overhead and, if your channel utilisation
is over 30%, it will have degrading effects on systems performance.  This is
especially critical if you have two CPUs sharing the same disk drives.
2    The model of control unit that is used for CRTs does make a big difference
in response time.  Choose the IBM 3174, if possible.  If using the IBM 3274
control units, stay away from the model 31D as it is very slow when heavily
loaded.  The 41D provides adequate response and may be needed depending on the

 type of terminals being supported.  For straight vanilla CRTs with no colour or
graphics support, the model 21B offers the best channel utilisation.
Medium impact
1    When selecting disk drives, if two storage directors are available, always
purchase the string switch feature.  This will provide an alternative path to
disk files and can save 20% or more in restarted seeks due to channel or control
unit busy.
2    Never put selector type devices like tape on the same channel as CRT
devices.  Also, depending on the speed of the tape drives used, you may find
that better response time can be obtained by putting CRTs on a lower channel
number than the tape drives.  This is especially true for slower speed tapes.
3    For proper tuning and best service, it is almost essential to have at least
one systems programmer who has received some education in CICS internals.
Low impact
1    A change log can be most helpful depending on the staff size and volume of
changes or new development going on.  When the system crashes, it is essential
to know as quickly as possible, what, if anything, has changed recently and what
was done to it.  This is true of both application program changes and systems
programming changes.
SUMMARY
As you can see, there are a large number of areas that you can look at and
review when tuning a CICS system.  We probably havenUt addressed them all but
will continue in the future to look, and to review, and to tune.  Our tuning
efforts have paid off well for us and, as a result, we feel we are making the
most of our investment in computer resources.  Our users are quite happy, and
therefore we as a company have improved our productivity.

Kenneth Marquardt
Manager Systems and Programming
Paper Converting Machine Co (USA)  ) Xephon 1988




































