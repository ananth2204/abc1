
Table Processing Part Two:  A New Approach
By Mark Yuhas

This second article in a two-part series will further address the
steps in table processing, including creating the tree structure
and generating the source.

Phase 3:  Creating the Tree Structure

This phase constructs the binary tree structure.  The previous
bubble sort has the array in the key sequence.  E.G., a table of
10 entries with keys:

  Entry1  - KEYA
  Entry2  - KEYB
  Entry3  - KEYC
  .
  .
  .
  Entry9  - KEYI
  Entry10 - KEYJ

where:

  KEYA < KEYB < KEYC < ... < KEYI < KEYJ

This sequenced structure allows the usage of an integer subset of
{1,2,3,..n} instead of Entry1, Entry2,...  I.E.:

  {1,2,3,..10} as opposed to {Entry1, Entry2, Entry3,...,Entry10}.

Yes, actually, the mapping is just using the subscripts of the
entries of the global array.  In the vernacular of the
mathematician, the array has a one-to-one and onto mapping to the
integer set.  This mapping also has another benefit--whatever
operation/sequencing performed on the integer set will hold for
the table as well.

Phase 3:  Creating the Tree Structure: The Specific Case
Defining the tree structure consists of a series of iterations of
determining the middle element of a series of subsets defined by
the results of the previous iteration.  Sounds a lot like a
binary search, which it is.  The mapping begins with the
endpoints and determination of the midpoint of the interval:

  {1,10} will yield a .midpoint of 5

  For:
    (1+10)/2 = 5

Now, the subset looks like:

  {1,5,10}

The next iteration yields new midpoints of 3 and 7:

  (1+5)/2 = 3  (5+10)/2 = 7

The subset becomes:

  {1,3,5(3,7),7,10}

  where A(B,C) is the notation to indicate that B is the element
  for the next iteration of the search if the key in element A is
  less than the target key. And, C is the next the element for
  the next iteration if the key in element A is greater than the
  target key.

The next iteration yields midpoints of 2, 4, 6 and 8:

  (1+3)/2=2   (3+5)/2=4    (5+7)/2=6    (7+10)/2=8

The subset is now:

  {1,2,3(2,4),4,5(3,7),6,7(6,8),8,10}

The next iteration yields midpoints of 1,0,0,0,0,0,0,9;

  (1+2)/2=1   (2+3)/2=0    (3+4)/2=0    (4+5)/2=0
  (5+6)/2=0   (6+7)/2=0    (7+8)/2=0    (8+10)/2=9

It should be obvious the 'zero midpoints' occur when the length
of any of the subset is 1.  In other words, the subset consists
of consecutive integers, which means the midpoint is nonexistent
or zero.  So why doesn't (1+2)/2=0?  By definition, These subset
{1,2} and {9,10} are special subsets that by definition do not
have midpoints.  Thus, the algorithm will not map to the
endpoints.  The only way to make this mapping a one-to-one and
onto mapping is by defining this condition for these subsets.

The subset is now:

  {1,2(1,0),3(2,4),4(0,0),5(3,7),6(0,0),7(6,8),8(0,9),9,10}

And, the final iteration yields:

  (1,2(1,0),3(2,4),4(0,0),5(3,7),6(0,0),7(6,8),8(0,9),9(0,10),10}

One more adjustment is needed.  You will notice 1 and 10 do not
have any pairs defined with them.  Actually, these elements will
always have the pairs of (0,0).  Why?  Suppose that one of these
had a 'nonzero midpoint.'  If this were true, then that would
mean that either the Minimum or Maximum was a midpoint of some
subset.  Again, if either of these was a midpoint, then a value
lower than the Minimum or the greater than the Maximum would
exist.  By definition, there cannot be such a value.  Therefore,
the Minimum and Maximum have null or '0' values.  This yields the
following structure:

 {1(0,0),2(1,0),3(2,4),4(0,0),5(3,7),6(0,0),7(6,8),8(0,9),9(0,10),10(0,0)}

Phase 3:  Creating the Tree Structure: The General Case
Using this information, the general case macro can be developed.
This general process requires the usage of 3 arrays:

  A master array that was inputted previously designated by the
  &G prefix

  2 local arrays for the iterative process designated &LTBL1 &
  &LTBL2, respectively

The first local array (&LTBL1) will contain the entries for each
iteration.  These entries are the endpoints for the subsets for
the subsequent midpoint determination and the previous midpoint
results.  The second array (&LTBL2) is a superset of the first
array containing &LTBL1 and the calculated midpoints.  At the end
of the iteration, &LTBL2 is moved to &LTBL1, establishing the
next subset for the next iteration.  This process continues until
the number of elements in the superset (&LTBL2) equals the number
of elements in the master array.

At the start of this procedure, first local array on has two
entries, the minimum (Min or 1) and the maximum (Max or &GINDEX).
Using these two values, the midpoint (Mid) can be calculated:

  Mid = (1+Max)/2

For lack of a better term, this is the 'seed' for the actual
search.  Remember the critical step to this process is finding
this "seed" to "kick start" the search procedure.  This yields a
new array:

  {1,Mid,Max}

Next, the midpoints of the two subsets are determined yielding
the first initial array of:

  {1, (1+Mid)/2, Mid, (Mid+Max)/2, Max}

Each element in the array is the index/subscript of the Master
array.  The Master array contains 3 additional elements:

  GLO    Index/subscript of the lower midpoint
  GHI      Index/subscript of the higher midpoint
  GDONE    Binary variable indicating whether GLO or GHI was set

The master array entries for Min (1) and Max (&GINDEX) have GLO
and GHI set to zero and GDONE is turned on.  The master array
entry for Mid has the corresponding GLO set to (1+Mid)/2, GHI set
to (Mid+Max)/2, and GDONE turned on.  Now, the iterations begin.

Each subset is defined by two consecutive entries in the first
local array, i.e. L2 & L2+1.  L3 is the index for LTBL2  The
control for each iteration is L1 whichL1, which contains the
number of elements in LTBL1 + 1.This is the framework for each
iteration:

Check for GDONE turned on.  If it is, move &LTBL1(&L2) to
&LTBL2(&L3) and increment &L2 and &L3, accordingly.

If the difference between &LTBL1(&L2) and &LTBL1(&L2-1) is
greater than 1, then calculate the new lower midpoint, and, then
address the high midpoint for the subset:
    {&LTBL1(&L2),&LTBL1(&L2+1)}

If &LTBL1(&L2) is equal to 2, then set GLO for &LTBL1(&L2) to 1,
move this entry to &LTBL2, set &L3 to 3, and, then address the
high midpoint for the subset:
    {&LTBL1(&L2),&LTBL1(&L2+1)}.

If &LTBL1(&L2) is greater than 2, then set GLO for &LTBL1(&L2) to
zero, move this entry to &LTBL2, increment &L3, and, then address
the high midpoint for the subset:
    {&LTBL1(&L2),&LTBL1(&L2+1)}.

For the high midpoint:

If the difference between &LTBL1(&L2) and &LTBL1(&L2+1) is
greater than 1, then calculate the new higher midpoint and then
increment &L2 and &L3 accordingly.

If &LTBL1(&L2+1) is equal to GINDEX, then set GHI for &LTBL1(&L2)
to GINDEX, move this entry to &LTBL2, set &L3 to 3 and then
increment &L2 and &L3 accordingly

If &LTBL1(&L2) is greater than 2, then set GHI for &LTBL1(&L2) to
    zero, move this entry to &LTBL2, increment &L3 and then
    address the high midpoint for the subset:
    {&LTBL1(&L2),&LTBL1(&L2+1)}.

Set GDONE to 1.

If all the entries of the array have been addressed, i.e.
&L2=&L1, this iteration is complete.

All the elements in &LTBL2 are moved to &LTBL1.  As they are
moved the count of elements for &LTBL1 is established for the
next iteration.  Also, the count of GDONE is kept track of in
&L4.

At the end of the move, if &L4 is equal to &GINDEX, the mapping
has completed.  If not, the next iteration control is in &L1 and
the corresponding entries in &LTBL1.

Phase 3:  Creating the Tree Structure: Verifying the Mapping
The mapping performed successfully for arrays with 10, 25, 50 and
100 entries.  However, a test of an array with 950 entries failed
with an error stating ACTR was negative.  ACTR is  the
conditional assembly language counter, thatcounter that begins
with a value and is decremented with every successful branch.
When ACTR contains a negative value, the assembler ends the
assembly.  This prevents loops in the assembly.

The programmer can set ACTR in the MACRO, but what to set it to?
1000?  2000?  It would be advantageous and elegant if the macro
could set ACTR according to the number of table entries.  Only
the sort and the tree mapping required revaluation of ACTR.

The bubble sort provided a fairly simple solution.  What
conditions would cause the most number of branches for the master
array?  That condition would arise if the master array were in
descending sequence.  The bubble sort would have to move every
entry in the master array.  How many iterations and how many
branches would this condition create?  The number of iterations
is the sum of the sequence:

  {GINDEX, GEINDEX-1, GEINDEX-2, ..., 3,2,1}

which is

  Ý(GINDEX+1)GINDEX¨/2

This yields the number of iterations.  Multiplying the number of
branches in the bubble sort by the sum of the sequence would
produce a value for ACTR.  It would be inflated because not every
branch is taken in any iteration.  The number would be too high,
which is preferable to too low.

The second consideration is the building of the tree structure.
This seemed like a SWAG.SWAG.  But it, too, had a simple
solution.  For the first iteration, LTBL1 has two elements.  For
the second, LTBL1 has 5.  The third has 11.  The fourth has 23.
Basically, the mapping doubles the local array until all elements
are addressed.  Thus, beginning with 4 or 22,this addresses the
first iteration.  8 or 23 addresses the second iteration.  16 or
24 addresses the third iteration. and  32 or 25 addresses the
fourth.  And so on.  This pattern continues until there is a
number n such that 2n is greater than GINDEX.  The number of
iterations is equal to the sum of the elements of the sequence:

  {4,8,16, ...,2n}

The following is a subset of the sequence.;

  {1,24,8,16, ...,2n}

This sum of the elements in the second sequence is:

  2n+1-1

Multiplying this sum by the total number of branches in the tree
building will yield a value for ACTR that will not be exceeded.

Phase 4:  Generating the Source
Generating the source for the individual table entries is pretty
straightforward.  Before building the source for each entry, the
macro generates the 'seed', i.e. TABLE_SEED.  This 'seed' is the
'kick-start' alluded to previously.

Each entry of the global array contains two fields that point to
the higher and lower midpoints.  Since each entry's
index/subscript is unique, this value can be used as a label,
i.e. ELEMENT_index.  This makes the generated table easier to
trace via the source listing.  Further, the pointers to the high
and low values can use the same ELEMENT_index, i.e. ELEMENT_high
& ELEMENT_low.  The generated table entry becomes:

TABLE_SEED    DC    A(ELEMENT_seed)
ELEMENT_0001  DC    C(TABLEKEY_0001_value),A(0),A(0)
              DC    table data
              .
              .
              .
ELEMENT_index DC C'TABLEKEY_index_valuex',A(ELEMENT_low),A(ELEMENT_high)
              DC    table data

This continues until the master array is exhausted.

It may appear that the individual table entries must have a
length divisible by 4 and that the key length must be divisible
by 4.  If not, then the entries will not be contiguous, as the
assembler will align the data values according to type and
length.  A simple revision of the table entry format yields:

  ELEMENT_index  DC A(ELEMENT_low),A(ELEMENT_high),C'TABLEKEY_index_value'
                 DC table data

Now, the entry will always be aligned on a full word boundary due
to the ADCON as the first field of the entry.  However, the full
word ADCON is superfluous.  The generated entry could easily be:

  ELEMENT_index  DC   AL4(ELEMENT_low),AL4(ELEMENT_high)
                 DC   C'TABLEKEY_inde_valuex',table data

This structure obviates the need for a full word boundary.  Going
one step further and redefining the table entry as:

  ELEMENT_index  DC   AL4(ELEMENT_low),AL4(ELEMENT_high), table data
                 DC   AL1(L'TABLEKEY_index)
  TABLEKEY_index DC   C'TABLEKEY_inde-valuex'

This structure yields a table with entries of variable length
with variable length keys.  Who would want to create something as
deviant?  I, for one.would do so because  I actually have a need
for a keyed table with this structure.  And, the macro generates
the source code just fine for a binary search using the tree
structure.

Finally, after all this work and contortions, this is the new
search code:

              L     R15,SEED_ADDRESS
  TREE_SEARCH DS    0H
              LTR   R15,R15
              BZ    NOT_FOUND
              CLC   SEARCH_FOR,0(R15)
              BE    FOUND
              BL    SET_LOW
              L     R15,HIGH_MIDPOINT
              B     TREE_SEARCH
  SET_LOW     DS    0H
              L     R15,LOW_MIDPOINT
              B     TREE_SEARCH
  FOUND       DS    0H


Finally, using this macro, the definition of a table can be
changed to:

  Entry    A set of fields in contiguous storage containing
           user-defined data.
  Table    A set of entries in storage.
           Contiguous is not a requirement because the macro will
           generate the addressing to the entries as needed.
  Key      An indexing field or fields of an entry.
           The key can be variable in length and still maintain
           the necessary structure because the macro will impose
           that structure via the tree structure mapping.

The revised binary search routine combines the brevity of the
code path of the serial search and the efficiency of the binary
search.  This search routine references neither the number of
entries nor the entry length.  In addition, duplicate entries
will not invalidate the integrity of the binary tree.
Furthermore, all of the intermediate calculations have been
eliminated.  The macro has replaced these calculations via the
tree structure construction during the assembly.  The assembly
will take longer, but it is a one-time performance hit.

Try it.  You just may like it.

