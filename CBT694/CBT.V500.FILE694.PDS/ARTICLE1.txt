Table Processing Part One: A New Approach
By Mark Yuhas

The intent of this article is to present a new approach to the
old subject of table processing.  We know Table processing is not
exactly focused on the leading edge of technology.  Furthermore,
many programmers - application and systems - have written search
routines, especially binary search routines.  The intent of this
article is to present a new approach to an old subject.


       Definition of Terms

  Entry          A set of fields in contiguous storage containing
                 user-defined data
  Table          A set of entries in contiguous storage
  Key            An indexing field or fields of an entry usually
                 fixed in length
  Keyed table    A table where the entries are ordered by a key
                 (For this discussion, the key will be restricted
                 to one field)
  Binary search  An iterative search process where the upper and
                 lower bounds of the keyed table are redefined by
                 the result of the key comparison in the previous
                 iteration
  Serial search  An iterative search process where the lower
                 bound of a table is redefined by the result of
                 the key comparison in the previous iteration.


The binary search requires a table with entries of a fixed length
and unique keys.  The serial search usually requires a table with
fixed-length entries.  However, certain table structures can
preventobviate the need for fixed-length entries.

Binary Versus Serial

Figure 1 contains an example of a serial search.  The path length
is short and concise.  If the routine doesn't find a match, it
will always examine the next entry.  Although the serial search
is very simple and straightforward, it is also inefficient and
time-cconsuming.  Time consuming because as the number of
entries increases, so does the time to search the table.  This is
even more time-consuming when one considers the 'hit ratio'---,
i.e. the number of times a matching entry is found versus the
number of times the search is performed.


    Figure 1 - Serial search code

                  LA    R14,TABLEA_START
                  LA    R15,TABLEA_STOP
  SERIAL_SEARCH   DS    0H
                  CLC   SEARCH_FOR,0(R14)
                  BNL   SEARCH_DONE
                  LA    R14,0(ENTRY_LENGTH,R14)
                  CR    R14,R15
                  BL    SERIAL_SEARCH
  SEARCH_DONE     DS    0H
            .
            .
            .
  SEARCH_FOR      DC    CL8'some value'
  TABLEA_START    EQU   *
                  DC    CL8'whatever'
  ENTRY_LENGTH    EQU   *-TABLEA_START
                  DS    CL??
                  DS    CL??
                  .
                  .
                  .
  TABLEA_STOP     EQU  *


Figure 2 contains an example of a binary search.

Figure 2:  The binary search of Table A:


                  LA    R14,TABLEA_START
                  LA    R15,TABLEA_STOP
  BINARY_SEARCH   DS    0H
                  XR    R10,R10
                  SR    R11,R15
                  SR    R11,R14
                  C     R11,=F'1'
                  BH    CONTINUE_SEARCH
                  CLC   SCAN_FOR,0(R14)
                  BE    SEARCH_DONE
                  CLC   SCAN_FOR,0(R15)
                  BE    SEARCH_DONE
                  B     SEARCH_FAIL
  CONTINUE_SEARCH DS    0H
                  D     R10,=A(ENTRY_LENGTH)
                  SRL   R11,1
                  XR    R10,R10
                  M     R10,=A(ENTRY_LENGTH)
                  AR    R11,R14
                  CLC   SCAN_FOR,0(R11)
                  BH    UPPER_HALF
                  BE    SEARCH_DONE
                  LR    R15,R11
                  B     BINARY_SEARCH
  UPPER_HALF      DS    0H
                  LR    R14,R11
                  B     BINARY_SEARCH
  SEARCH_DONE     DS    0H
                  .
                  .
                  .
  SEARCH_FAIL     DS    0H
                  .
                  .
                  .
  SEARCH_FOR      DC    CL8'some value'
  TABLEA_START    EQU   *
                  DC    CL8'whatever'
                  DS    CL??
                  DS    CL??
  ENTRY_LENGTH    EQU   *-TABLEA_START
                  .
                  .
                  .
  TABLEA_STOP     EQU  *


While the binary search code has a longer path, it is much more
efficient.  The binary search becomes more efficient as the table
size increases, as this chart shows:

  # of Entries    Maximum Search Iterations    Average Search Iterations
  ------------    -------------------------    -------------------------
  10               Binary  5                        3.3
                  Serial  10                        5.5

  100              Binary  8                        6.3
                  Serial  100                      50.5

  1000             Binary  11                       9.2
                  Serial  1000                    500.5

  10000            Binary  15                      12.9
                  Serial  10000                  5000.5

Once again, stating the obvious, the binary search is much more
efficient, even for tables with a small number of entries.

Closer Scrutiny of the Binary Search

Despite being quite efficient, the binary search will invariably
examine the same entries for a given search argument for each
search invocation.  For example, the binary search of a table of
100 entries would have this standard search sequence for Entry
#76:

  Entry #50, Entry #75, Entry #87, Entry #81, Entry #78, Entry #76

If this sequence is known, why should the search routine perform
the calculations to determine the next entry to examine?  The
efficiency of the binary search would be dramatically improved if
this search sequence could be mapped prior to invocation.

Attempts to derive an algorithm/mapping to identify this search
sequence proved to be fruitless.  However, a construct called the
binary tree table appeared to provide the desired mapping.  In
this construct, each entry points to its higher and lower
entries for the next search iteration--, i.e. the midpoint of the
next interval.  The definition of the next interval being
determined by the comparison for the current interval (, for
example, e.g. for a table of 10 entries):

  #1 points to null & null
  #2 points to null & #1
  #3 points to #4 & #2
  #4 points to null & null
  #5 points to #7 & #3
  #6 points to null & null
  #7 points to #8 & #6
  #8 points to #9 & null
  #9 points to #10 & null
  #10 points to null & null

Once the midpoint of the array is found, the search proceeds in a
cascade effect with each subsequent iteration determined only by
the result of the previous iteration's comparison.  This is
better illustrated in Figure 3:



When to Map the Tree

A run-time programmatic solution seemed to be the fastest method
to impose the tree structure on the table.  A programmatic
solution would also provide the flexibility needed when the table
size changed.  Further, the programmatic solution was immensely
faster and more accurate than any manual method.  This approach
had a major flaw--, i.e. any user/application/service requiring
access to the table would have to wait until the programmatic
solution completed.  Thus, the tree structure needed to be
created with the table itself.  In other words, the structure
would have to be part of the source code.  Since any addition or
deletion of entries would change the structure, the source code
would have to change accordingly.  This type of flexibility and
speed could only be achieved via a MACRO.

Before I begin the explanation of the MACRO, I should make
something clear.  I am not omniscient, nor, do I mind-meld with
the machine.  There are probably as many approaches to coding
this MACRO as there are readers.  My intent here is to explain
how I was able to achieve a faster search mechanism by defining
the tree structure via this MACRO.

The MACRO required 4 phases:

  Input, editing and retention of table entries
  Sorting the table entries
  Creating the tree structure
  Generating the source

Phase 1:  Input, Editing and Retention of Table Entries

First, any macro that builds individual table entries can be
used.  Modifying the existing macro to build the individual
entries and save them in a global array performs the input
portion.  Figure 4 lists the MACRO declarations.  The pointer for
the current array entry is &GINDEX.  This variable will also
serve as the control for the subsequent loops in the other
phases.  Also, the declarations include the local array LTBL1 and
LTBL2, which are critical for the deriving the tree structure.

&NAME  TREEMAC  &MSGID,        +
                &FLAG1=OFF,    +
                &FLAG2=OFF,    +
                &FLAG3=OFF,    +
                &FLAG4=OFF,    +
                &FLAG5=OFF,    +
                &FLAG6=OFF,    +
                &FLAG7=OFF,    +
                &FLAG8=OFF,    +
                &MESSAGE=NO,   +
                &PROCESS=NO,   +
                &USEID=
        GBLC    &GSORTKEY(1500)
        GBLC    &GMSGID(1500)
        GBLC    &GFLAG1(1500)
        GBLC    &GFLAG2(1500)
        GBLC    &GFLAG3(1500)
        GBLC    &GFLAG4(1500)
        GBLC    &GFLAG5(1500)
        GBLC    &GFLAG6(1500)
        GBLC    &GFLAG7(1500)
        GBLC    &GFLAG8(1500)
        GBLC    &GMESSAGE(1500)
        GBLC    &GPROCESS(1500)
        GBLA    &GLO(1500)
        GBLA    &GHI(1500)
        GBLB    &GDONE(1500)
        GBLA    &GINDEX
        GBLA    &GTBLNO
        LCLC    &LSORTKEY
        LCLC    &LMSGID
        LCLC    &LFLAG1
        LCLC    &LFLAG2
        LCLC    &LFLAG3
        LCLC    &LFLAG4
        LCLC    &LFLAG5
        LCLC    &LFLAG6
        LCLC    &LFLAG7
        LCLC    &LFLAG8
        LCLC    &LMESSAGE
        LCLC    &LPROCESS
        LCLA    &LLO
        LCLA    &LHI
        LCLA    &LSEED
        LCLA    &L1
        LCLA    &L2
        LCLA    &L3
        LCLA    &L4
        LCLA    &L5
        LCLA    &L6
        LCLA    &L7
        LCLA    &L8
        LCLA    &L9
        LCLA    &LTBL1(1500)
        LCLA    &LTBL2(1500)


Second, Phase 1 needs a method to control the starting and
stopping of the population of the array.  This control method was
achieved through the definition of specific key values indicating
the beginning and end of this phase--, i.e. TABLE_START &
TABLE_STOP.  TABLE_START initializes the global variables for
subsequent processing.  TABLE_STOP establishes the limits for the
subsequent source and sets variables disabling any further
invocations to create any further array entries.

Phase 2:  Sorting the Table Eentries

Sorting proved to be an interesting exercise in itself.  The
bubble sort technique was used.  Storage was not a restriction,
and processing time was more than ample.  However, after coding
the sort, an attempt to sort a table with 10 entries was made.
Lo and behold, the sort results were strange.  Keys with higher
values were lower in the collation, and, vice versa.  For
example, if the table contained keys of:

                         ABCD, ABC, CB, XYZ, Z, YZ

the sorted result would be:

                         Z, CB, YZ, ABC, XYZ, ABCD

Apparently, in the macro world, the lengths of the variables are
compared before comparing the variables themselves.  This wrinkle
required a modification to the bubble sort, where a comparison of
the lengths would determine which length to use for the
subsequent comparison.  Or, Phase 1 could be altered to add
another field to the global array.  This new field would contain
a left-justified key padded with blanks.  This field would
become the key field for the sort.  This modification reduced a
lot of extraneous coding and left the actual fields of the entry
alone.  Refer to Figure 4 and the variable &GSORTKEY.  When the
MACRO detects another element for the array, the MACRO checks the
length of the key, and, if necessary, pads the key value with
blanks in &GSORTKEY.

Conclusion

By design, this table has unique keys.  When the bubble sort
detects a duplicate key, the macro ends with an appropriate MNOTE
detailing the equal keys.  In part two However, later in the
article,we will see that  duplicate keys do not affect the
integrity of the table. We will also address the next two phases
in part two of this article.

Mark Yuhas I has worked have been in in the IT area for 31 years,
including the last 19 years of experience as an MVS systems
programmer.


